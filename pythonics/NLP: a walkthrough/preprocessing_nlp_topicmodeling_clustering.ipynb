{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- One project idea for this Friday would be to compare all the different versions of the bible, see how they compare on sentiment, etc.--pulling via BeautifulSoup from this website:\n",
    "http://www.biblestudytools.com/bible-versions/. But this is a more academic project in nature; something that could be published as an article of the form \"what can natural language processing have to say about religion?\" type of deal. 'computational theology', i.e. (is there such a thing as computational theology? if so, what could it look like?) -- this would be a good quick side project ;)\n",
    "\n",
    "- Another direction will be semantic analysis. Ultimately the more profitable way to go. Just stick with the single text for now, stick it into gensim, see what comes of it. Will probs involve PCA.\n",
    "\n",
    "- Another direction will be PCA --> Kmeans/K++ clustering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# from pymongo import MongoClient\n",
    "# import pymongo\n",
    "\n",
    "# import numpy as np\n",
    "# import pandas as pd\n",
    "# import nltk\n",
    "# from collections import defaultdict\n",
    "# import unicodedata \n",
    "# import string \n",
    "# #import soundex #-->requires repoze.lru??\n",
    "# #from nltk.tokenize import sent_tokenize\n",
    "# #from nltk.tokenize import TreebankWordTokenizer\n",
    "# from tqdm import tqdm\n",
    "# import re\n",
    "# import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 428,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#NLpre-P\n",
    "import re\n",
    "import pymongo\n",
    "from tqdm import tqdm\n",
    "import pickle\n",
    "import pandas as pd\n",
    "\n",
    "#NLP\n",
    "import nltk\n",
    "from nltk.tag import pos_tag\n",
    "from textblob import TextBlob\n",
    "from gensim import corpora, models, similarities\n",
    "import logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import pymongo\n",
    "\n",
    "client = pymongo.MongoClient()\n",
    "geist = client.geist_db\n",
    "bible = client.geist_db.bible_collection\n",
    "\n",
    "#bible.drop() # Clear out any data we had in the collection.\n",
    "\n",
    "for review in reviews:\n",
    "    hmm.save(review)\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###0. get data from pgiso ... this will come\n",
    "for now, just starting with a single example..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ". csvs --> mongo (still have to add the 'to mongo' part)  (would be nice but for now...)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###1. get documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_docs(filename, form='gutenberg'):\n",
    "    '''Converts a file into documents. Documents are separated by blank lines in the file.'''\n",
    "    \n",
    "    f = open(filename)\n",
    "    startline = 100\n",
    "    endline = 1000000\n",
    "    documents = []\n",
    "    document = ''    \n",
    "    if form == 'gutenberg':\n",
    "        start = \"*** START OF THIS PROJECT GUTENBERG EBOOK\"\n",
    "        end = \"*** END OF THIS PROJECT GUTENBERG EBOOK\"\n",
    "\n",
    "    for i, line in enumerate(f):\n",
    "        if start in line:\n",
    "            startline = i\n",
    "        if end in line:\n",
    "            endline = i\n",
    "        if i > startline and i < endline:\n",
    "            #Beginning of Document\n",
    "            if line.strip():  \n",
    "                document += line[:-2]\n",
    "            #End of Document\n",
    "            else: \n",
    "                if document != '' and isinstance(document, str):\n",
    "                    for word in document:\n",
    "                        if word in stopwords:\n",
    "                            document.replace(word, '')\n",
    "                    documents.append(document)\n",
    "                    document = ''\n",
    "    f.close()\n",
    "    return documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "docs_bible = get_docs('bible.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The Old Testament of the King James Version of the Bible',\n",
       " 'The First Book of Moses:  Called Genesis',\n",
       " '1:1 In the beginning God created the heaven and the earth.',\n",
       " '1:2 And the earth was without form, and void; and darkness was uponthe face of the deep. And the Spirit of God moved upon the face of thewaters.',\n",
       " '1:3 And God said, Let there be light: and there was light.',\n",
       " '1:4 And God saw the light, that it was good: and God divided the lightfrom the darkness.',\n",
       " '1:5 And God called the light Day, and the darkness he called Night.And the evening and the morning were the first day.',\n",
       " '1:6 And God said, Let there be a firmament in the midst of the waters,and let it divide the waters from the waters.',\n",
       " '1:7 And God made the firmament, and divided the waters which wereunder the firmament from the waters which were above the firmament:and it was so.',\n",
       " '1:8 And God called the firmament Heaven. And the evening and themorning were the second day.']"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs_bible[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#1. alla the bibles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "versions = {  #27\n",
    "'American Standard Version':'ASV',\n",
    "'English Standard Version':'ESV',\n",
    "'GOD\\'S WORD Translation':'GW',\n",
    "'Good News Translation':'GNT',\n",
    "'Holman Christian Standard Bible':'CSB',\n",
    "'Jubilee Bible 2000':'JUB',\n",
    "'King James Version':'KJV',\n",
    "'Lexham English Bible':'LEB',\n",
    "'Douay-Rhiems Catholic Bible':'RHE',\n",
    "'New American Standard Bible':'NAS',\n",
    "'New International Version':'NIV',\n",
    "'New King James Version':'NKJV',\n",
    "'New Living Translation':'NLT',\n",
    "'New Revised Standard':'NRS',\n",
    "'Revised Standard Version':'RSV',\n",
    "'The Message Bible':'MSG',\n",
    "'Hebrew Names Version':'HNV',\n",
    "'New Century Version':'NCV',\n",
    "'New International Reader\\'s Version':'NIRV',\n",
    "'The Bible in Basic English':'BBE',\n",
    "'The Complete Jewish Bible':'CJB',\n",
    "'Third Millennium Bible':'TMB',\n",
    "'World English Bible':'WEB',\n",
    "'Young\\'s Literal Translation':'YLT',\n",
    "'The Darby Translation':'DBY',\n",
    "'The Webster Bible':'WBT',\n",
    "'Wycliffe':'WYC'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(\"bibles_data_1.pkl\", 'r') as picklefile: \n",
    "    bibles_data_1 = pickle.load(picklefile)\n",
    "with open(\"bibles_data_2.pkl\", 'r') as picklefile: \n",
    "    bibles_data_2 = pickle.load(picklefile)\n",
    "with open(\"bibles_data_3.pkl\", 'r') as picklefile: \n",
    "    bibles_data_3 = pickle.load(picklefile)\n",
    "with open(\"bibles_data_4.pkl\", 'r') as picklefile: \n",
    "    bibles_data_4 = pickle.load(picklefile)\n",
    "with open(\"bibles_data_5.pkl\", 'r') as picklefile: \n",
    "    bibles_data_5 = pickle.load(picklefile)\n",
    "with open(\"bibles_data_6.pkl\", 'r') as picklefile: \n",
    "    bibles_data_6 = pickle.load(picklefile)\n",
    "with open(\"bibles_data_7.pkl\", 'r') as picklefile: \n",
    "    bibles_data_7 = pickle.load(picklefile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 436,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#the ones with the metadata\n",
    "\n",
    "with open(\"bibles_w_metadata_1.pkl\", 'r') as picklefile: \n",
    "    bibles_data_metadata_1 = pickle.load(picklefile)\n",
    "with open(\"bibles_w_metadata_2.pkl\", 'r') as picklefile: \n",
    "    bibles_data_metadata_2 = pickle.load(picklefile)\n",
    "with open(\"bibles_w_metadata_3.pkl\", 'r') as picklefile: \n",
    "    bibles_data_metadata_3 = pickle.load(picklefile)\n",
    "with open(\"bibles_w_metadata_4.pkl\", 'r') as picklefile: \n",
    "    bibles_data_metadata_4 = pickle.load(picklefile)\n",
    "with open(\"bibles_w_metadata_5.pkl\", 'r') as picklefile: \n",
    "    bibles_data_metadata_5 = pickle.load(picklefile)\n",
    "with open(\"bibles_w_metadata_6.pkl\", 'r') as picklefile: \n",
    "    bibles_data_metadata_6 = pickle.load(picklefile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 437,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bibles_data_metadata = [bibles_data_metadata_1, bibles_data_metadata_2, \n",
    "                        bibles_data_metadata_3, bibles_data_metadata_4, \n",
    "                        bibles_data_metadata_5, bibles_data_metadata_6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bibles_data = [bibles_data_1, bibles_data_2, bibles_data_3, bibles_data_4,\n",
    "              bibles_data_5, bibles_data_6, bibles_data_7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "client = pymongo.MongoClient()\n",
    "bibles = client.legislation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "#in mongo -- probs need to be more organized to use this-- \n",
    "# would be good at a more granular level?\n",
    "\n",
    "for b in bibles_data:\n",
    "    for name, docs in b.items():\n",
    "        versions[name] = bibles.versions[name]\n",
    "        for i, document in tqdm(enumerate(docs)):\n",
    "            versions[name].save({str(i): document})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bibles_df = pd.DataFrame()\n",
    "for b in bibles_data:\n",
    "    for name, docs in b.items():\n",
    "        bibles_df[name] = docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 442,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bibles_metadata_df = pd.DataFrame()\n",
    "for b in bibles_data_metadata:\n",
    "    for name, docs_dict in b.items():\n",
    "        docs = []\n",
    "        indices = []\n",
    "        for book_chap_key, doc in docs_dict.items():\n",
    "            docs.append(doc)\n",
    "            indices.append(book_chap_key)\n",
    "        bibles_metadata_df[name] = docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 462,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bibles_metadata_df.index = indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 467,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "genesis_df = bibles_metadata_df\n",
    "for index, row in bibles_metadata_df.iterrows():\n",
    "    if index[0] != 'Genesis':\n",
    "        genesis_df = genesis_df.drop(index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 469,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50"
      ]
     },
     "execution_count": 469,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(genesis_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 466,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>American Standard Version</th>\n",
       "      <th>Good News Translation</th>\n",
       "      <th>Holman Christian Standard Bible</th>\n",
       "      <th>GOD'S WORD Translation</th>\n",
       "      <th>Jubilee Bible 2000</th>\n",
       "      <th>Lexham English Bible</th>\n",
       "      <th>King James Version</th>\n",
       "      <th>Douay-Rhiems Catholic Bible</th>\n",
       "      <th>New King James Version</th>\n",
       "      <th>...</th>\n",
       "      <th>Hebrew Names Version</th>\n",
       "      <th>The Message Bible</th>\n",
       "      <th>World English Bible</th>\n",
       "      <th>Third Millennium Bible</th>\n",
       "      <th>The Bible in Basic English</th>\n",
       "      <th>The Complete Jewish Bible</th>\n",
       "      <th>The Webster Bible</th>\n",
       "      <th>Young's Literal Translation</th>\n",
       "      <th>Wycliffe</th>\n",
       "      <th>The Darby Translation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(Psalms, 52)</td>\n",
       "      <td>Why boaste...</td>\n",
       "      <td>Why do you...</td>\n",
       "      <td>God Judges the ProudFor the choir director A D...</td>\n",
       "      <td>Why do you...</td>\n",
       "      <td>Why dost t...</td>\n",
       "      <td>For the music director A maskil of David When ...</td>\n",
       "      <td>Why boaste...</td>\n",
       "      <td>Unto the ...</td>\n",
       "      <td>To the Chi...</td>\n",
       "      <td>...</td>\n",
       "      <td>Why do yo...</td>\n",
       "      <td>Why do you...</td>\n",
       "      <td>Why do yo...</td>\n",
       "      <td>Why boast...</td>\n",
       "      <td>Purposing ...</td>\n",
       "      <td>For the le...</td>\n",
       "      <td>To the chi...</td>\n",
       "      <td>To the Ove...</td>\n",
       "      <td>To victory...</td>\n",
       "      <td>To the chi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(Habakkuk, 3)</td>\n",
       "      <td>A prayer o...</td>\n",
       "      <td>This is a ...</td>\n",
       "      <td>Habakkuks Third Prayer                        ...</td>\n",
       "      <td>A prayer o...</td>\n",
       "      <td>A prayer of Habakkuk the prophet because of al...</td>\n",
       "      <td>The Prayer of Habakkuk                        ...</td>\n",
       "      <td>A prayer o...</td>\n",
       "      <td>A PRAYER O...</td>\n",
       "      <td>A prayer o...</td>\n",
       "      <td>...</td>\n",
       "      <td>A prayer o...</td>\n",
       "      <td>A prayer o...</td>\n",
       "      <td>A prayer o...</td>\n",
       "      <td>A prayer o...</td>\n",
       "      <td>A prayer o...</td>\n",
       "      <td>This is a ...</td>\n",
       "      <td>A prayer o...</td>\n",
       "      <td>A prayer o...</td>\n",
       "      <td>The prayer...</td>\n",
       "      <td>A Prayer o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(1-Chronicles, 29)</td>\n",
       "      <td>And David ...</td>\n",
       "      <td>King David...</td>\n",
       "      <td>Contributions for Building the Temple         ...</td>\n",
       "      <td>Then King ...</td>\n",
       "      <td>Furthermor...</td>\n",
       "      <td>Offerings for the Temple                      ...</td>\n",
       "      <td>Furthermor...</td>\n",
       "      <td>And king D...</td>\n",
       "      <td>Furthermor...</td>\n",
       "      <td>...</td>\n",
       "      <td>David the ...</td>\n",
       "      <td>Then David...</td>\n",
       "      <td>David the ...</td>\n",
       "      <td>Furthermor...</td>\n",
       "      <td>And David ...</td>\n",
       "      <td>To the who...</td>\n",
       "      <td>Furthermor...</td>\n",
       "      <td>And David ...</td>\n",
       "      <td>And king D...</td>\n",
       "      <td>And king D...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(Revelation, 1)</td>\n",
       "      <td>The Revela...</td>\n",
       "      <td>This book ...</td>\n",
       "      <td>Prologue                                    Th...</td>\n",
       "      <td>This is th...</td>\n",
       "      <td>The Revela...</td>\n",
       "      <td>Prologue                                    Th...</td>\n",
       "      <td>The Revela...</td>\n",
       "      <td>The Revela...</td>\n",
       "      <td>The Revela...</td>\n",
       "      <td>...</td>\n",
       "      <td>This is th...</td>\n",
       "      <td>A revealin...</td>\n",
       "      <td>This is th...</td>\n",
       "      <td>The Revela...</td>\n",
       "      <td>The Revela...</td>\n",
       "      <td>This is th...</td>\n",
       "      <td>The Revela...</td>\n",
       "      <td>A revelati...</td>\n",
       "      <td>Apocalypse...</td>\n",
       "      <td>Revelation...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(Deuteronomy, 17)</td>\n",
       "      <td>Thou shalt...</td>\n",
       "      <td>Do not sac...</td>\n",
       "      <td>You must n...</td>\n",
       "      <td>Never offe...</td>\n",
       "      <td>Thou shalt...</td>\n",
       "      <td>You shall ...</td>\n",
       "      <td>Thou shalt...</td>\n",
       "      <td>Thou shalt...</td>\n",
       "      <td>You shall ...</td>\n",
       "      <td>...</td>\n",
       "      <td>You shall ...</td>\n",
       "      <td>And dont s...</td>\n",
       "      <td>You shall ...</td>\n",
       "      <td>Thou shalt...</td>\n",
       "      <td>No ox or s...</td>\n",
       "      <td>You are no...</td>\n",
       "      <td>Thou shalt...</td>\n",
       "      <td>Thou dost ...</td>\n",
       "      <td>Thou shalt...</td>\n",
       "      <td>Thou shalt...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                index                          American Standard Version  \\\n",
       "0        (Psalms, 52)                                      Why boaste...   \n",
       "1       (Habakkuk, 3)                                      A prayer o...   \n",
       "2  (1-Chronicles, 29)                                      And David ...   \n",
       "3     (Revelation, 1)                                      The Revela...   \n",
       "4   (Deuteronomy, 17)                                      Thou shalt...   \n",
       "\n",
       "                               Good News Translation  \\\n",
       "0                                      Why do you...   \n",
       "1                                      This is a ...   \n",
       "2                                      King David...   \n",
       "3                                      This book ...   \n",
       "4                                      Do not sac...   \n",
       "\n",
       "                     Holman Christian Standard Bible  \\\n",
       "0  God Judges the ProudFor the choir director A D...   \n",
       "1  Habakkuks Third Prayer                        ...   \n",
       "2  Contributions for Building the Temple         ...   \n",
       "3  Prologue                                    Th...   \n",
       "4                                      You must n...   \n",
       "\n",
       "                              GOD'S WORD Translation  \\\n",
       "0                                      Why do you...   \n",
       "1                                      A prayer o...   \n",
       "2                                      Then King ...   \n",
       "3                                      This is th...   \n",
       "4                                      Never offe...   \n",
       "\n",
       "                                  Jubilee Bible 2000  \\\n",
       "0                                      Why dost t...   \n",
       "1  A prayer of Habakkuk the prophet because of al...   \n",
       "2                                      Furthermor...   \n",
       "3                                      The Revela...   \n",
       "4                                      Thou shalt...   \n",
       "\n",
       "                                Lexham English Bible  \\\n",
       "0  For the music director A maskil of David When ...   \n",
       "1  The Prayer of Habakkuk                        ...   \n",
       "2  Offerings for the Temple                      ...   \n",
       "3  Prologue                                    Th...   \n",
       "4                                      You shall ...   \n",
       "\n",
       "                                  King James Version  \\\n",
       "0                                      Why boaste...   \n",
       "1                                      A prayer o...   \n",
       "2                                      Furthermor...   \n",
       "3                                      The Revela...   \n",
       "4                                      Thou shalt...   \n",
       "\n",
       "                         Douay-Rhiems Catholic Bible  \\\n",
       "0                                       Unto the ...   \n",
       "1                                      A PRAYER O...   \n",
       "2                                      And king D...   \n",
       "3                                      The Revela...   \n",
       "4                                      Thou shalt...   \n",
       "\n",
       "                              New King James Version  \\\n",
       "0                                      To the Chi...   \n",
       "1                                      A prayer o...   \n",
       "2                                      Furthermor...   \n",
       "3                                      The Revela...   \n",
       "4                                      You shall ...   \n",
       "\n",
       "                         ...                          \\\n",
       "0                        ...                           \n",
       "1                        ...                           \n",
       "2                        ...                           \n",
       "3                        ...                           \n",
       "4                        ...                           \n",
       "\n",
       "                                Hebrew Names Version  \\\n",
       "0                                       Why do yo...   \n",
       "1                                      A prayer o...   \n",
       "2                                      David the ...   \n",
       "3                                      This is th...   \n",
       "4                                      You shall ...   \n",
       "\n",
       "                                   The Message Bible  \\\n",
       "0                                      Why do you...   \n",
       "1                                      A prayer o...   \n",
       "2                                      Then David...   \n",
       "3                                      A revealin...   \n",
       "4                                      And dont s...   \n",
       "\n",
       "                                 World English Bible  \\\n",
       "0                                       Why do yo...   \n",
       "1                                      A prayer o...   \n",
       "2                                      David the ...   \n",
       "3                                      This is th...   \n",
       "4                                      You shall ...   \n",
       "\n",
       "                              Third Millennium Bible  \\\n",
       "0                                       Why boast...   \n",
       "1                                      A prayer o...   \n",
       "2                                      Furthermor...   \n",
       "3                                      The Revela...   \n",
       "4                                      Thou shalt...   \n",
       "\n",
       "                          The Bible in Basic English  \\\n",
       "0                                      Purposing ...   \n",
       "1                                      A prayer o...   \n",
       "2                                      And David ...   \n",
       "3                                      The Revela...   \n",
       "4                                      No ox or s...   \n",
       "\n",
       "                           The Complete Jewish Bible  \\\n",
       "0                                      For the le...   \n",
       "1                                      This is a ...   \n",
       "2                                      To the who...   \n",
       "3                                      This is th...   \n",
       "4                                      You are no...   \n",
       "\n",
       "                                   The Webster Bible  \\\n",
       "0                                      To the chi...   \n",
       "1                                      A prayer o...   \n",
       "2                                      Furthermor...   \n",
       "3                                      The Revela...   \n",
       "4                                      Thou shalt...   \n",
       "\n",
       "                         Young's Literal Translation  \\\n",
       "0                                      To the Ove...   \n",
       "1                                      A prayer o...   \n",
       "2                                      And David ...   \n",
       "3                                      A revelati...   \n",
       "4                                      Thou dost ...   \n",
       "\n",
       "                                            Wycliffe  \\\n",
       "0                                      To victory...   \n",
       "1                                      The prayer...   \n",
       "2                                      And king D...   \n",
       "3                                      Apocalypse...   \n",
       "4                                      Thou shalt...   \n",
       "\n",
       "                               The Darby Translation  \n",
       "0                                      To the chi...  \n",
       "1                                      A Prayer o...  \n",
       "2                                      And king D...  \n",
       "3                                      Revelation...  \n",
       "4                                      Thou shalt...  \n",
       "\n",
       "[5 rows x 25 columns]"
      ]
     },
     "execution_count": 466,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_new = bibles_metadata_df.reset_index()\n",
    "df_new.head()\n",
    "\n",
    "\n",
    "\n",
    "# df = df.reset_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 464,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 1/24 [00:04<01:44,  4.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "American Standard Version\n",
      "Good News Translation"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  8%|▊         | 2/24 [00:07<01:28,  4.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Holman Christian Standard Bible"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 12%|█▎        | 3/24 [00:10<01:20,  3.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "GOD'S WORD Translation"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 17%|█▋        | 4/24 [00:13<01:08,  3.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Jubilee Bible 2000"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 21%|██        | 5/24 [00:15<00:59,  3.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Lexham English Bible"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 25%|██▌       | 6/24 [00:19<00:59,  3.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "King James Version"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 29%|██▉       | 7/24 [00:22<00:53,  3.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Douay-Rhiems Catholic Bible"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 33%|███▎      | 8/24 [00:24<00:47,  2.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "New King James Version"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 38%|███▊      | 9/24 [00:27<00:42,  2.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "New Living Translation"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 42%|████▏     | 10/24 [00:29<00:38,  2.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The Message Bible"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 46%|████▌     | 11/24 [00:32<00:34,  2.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Hebrew Names Version"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 50%|█████     | 12/24 [00:34<00:31,  2.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "New Revised Standard"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 54%|█████▍    | 13/24 [00:37<00:28,  2.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Revised Standard Version"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 58%|█████▊    | 14/24 [00:39<00:25,  2.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The Complete Jewish Bible"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 62%|██████▎   | 15/24 [00:42<00:22,  2.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The Bible in Basic English"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 67%|██████▋   | 16/24 [00:44<00:19,  2.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "New Century Version"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 71%|███████   | 17/24 [00:46<00:17,  2.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "New International Reader's Version"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 75%|███████▌  | 18/24 [00:49<00:15,  2.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "World English Bible"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 79%|███████▉  | 19/24 [00:52<00:12,  2.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Young's Literal Translation"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 83%|████████▎ | 20/24 [00:54<00:09,  2.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Third Millennium Bible"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 88%|████████▊ | 21/24 [00:57<00:07,  2.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The Webster Bible"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 92%|█████████▏| 22/24 [00:59<00:04,  2.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Wycliffe"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 96%|█████████▌| 23/24 [01:03<00:03,  3.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The Darby Translation"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                               "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "version_names_metadata = cleaned_bibles_df.columns.tolist()\n",
    "\n",
    "###### allathabibles -- with metadata indices -- ######\n",
    "\n",
    "count_vectorized_bibles_w_metadata = {}\n",
    "for name in tqdm(version_names_metadata):\n",
    "    vectorizer = CountVectorizer(stop_words=archaic_stopwords, \n",
    "                             token_pattern='[A-Za-z]+', min_df=2)\n",
    "    single_bible_corpus = bibles_metadata_df[name]\n",
    "    print name\n",
    "    vectorized = vectorizer.fit_transform(single_bible_corpus)\n",
    "    count_vectorized_bibles_w_metadata[name] = (vectorizer, vectorized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 463,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>American Standard Version</th>\n",
       "      <th>Good News Translation</th>\n",
       "      <th>Holman Christian Standard Bible</th>\n",
       "      <th>GOD'S WORD Translation</th>\n",
       "      <th>Jubilee Bible 2000</th>\n",
       "      <th>Lexham English Bible</th>\n",
       "      <th>King James Version</th>\n",
       "      <th>Douay-Rhiems Catholic Bible</th>\n",
       "      <th>New King James Version</th>\n",
       "      <th>New Revised Standard</th>\n",
       "      <th>...</th>\n",
       "      <th>Hebrew Names Version</th>\n",
       "      <th>The Message Bible</th>\n",
       "      <th>World English Bible</th>\n",
       "      <th>Third Millennium Bible</th>\n",
       "      <th>The Bible in Basic English</th>\n",
       "      <th>The Complete Jewish Bible</th>\n",
       "      <th>The Webster Bible</th>\n",
       "      <th>Young's Literal Translation</th>\n",
       "      <th>Wycliffe</th>\n",
       "      <th>The Darby Translation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>(Psalms, 52)</th>\n",
       "      <td>Why boaste...</td>\n",
       "      <td>Why do you...</td>\n",
       "      <td>God Judges the ProudFor the choir director A D...</td>\n",
       "      <td>Why do you...</td>\n",
       "      <td>Why dost t...</td>\n",
       "      <td>For the music director A maskil of David When ...</td>\n",
       "      <td>Why boaste...</td>\n",
       "      <td>Unto the ...</td>\n",
       "      <td>To the Chi...</td>\n",
       "      <td>Why do you...</td>\n",
       "      <td>...</td>\n",
       "      <td>Why do yo...</td>\n",
       "      <td>Why do you...</td>\n",
       "      <td>Why do yo...</td>\n",
       "      <td>Why boast...</td>\n",
       "      <td>Purposing ...</td>\n",
       "      <td>For the le...</td>\n",
       "      <td>To the chi...</td>\n",
       "      <td>To the Ove...</td>\n",
       "      <td>To victory...</td>\n",
       "      <td>To the chi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(Habakkuk, 3)</th>\n",
       "      <td>A prayer o...</td>\n",
       "      <td>This is a ...</td>\n",
       "      <td>Habakkuks Third Prayer                        ...</td>\n",
       "      <td>A prayer o...</td>\n",
       "      <td>A prayer of Habakkuk the prophet because of al...</td>\n",
       "      <td>The Prayer of Habakkuk                        ...</td>\n",
       "      <td>A prayer o...</td>\n",
       "      <td>A PRAYER O...</td>\n",
       "      <td>A prayer o...</td>\n",
       "      <td>A prayer o...</td>\n",
       "      <td>...</td>\n",
       "      <td>A prayer o...</td>\n",
       "      <td>A prayer o...</td>\n",
       "      <td>A prayer o...</td>\n",
       "      <td>A prayer o...</td>\n",
       "      <td>A prayer o...</td>\n",
       "      <td>This is a ...</td>\n",
       "      <td>A prayer o...</td>\n",
       "      <td>A prayer o...</td>\n",
       "      <td>The prayer...</td>\n",
       "      <td>A Prayer o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(1-Chronicles, 29)</th>\n",
       "      <td>And David ...</td>\n",
       "      <td>King David...</td>\n",
       "      <td>Contributions for Building the Temple         ...</td>\n",
       "      <td>Then King ...</td>\n",
       "      <td>Furthermor...</td>\n",
       "      <td>Offerings for the Temple                      ...</td>\n",
       "      <td>Furthermor...</td>\n",
       "      <td>And king D...</td>\n",
       "      <td>Furthermor...</td>\n",
       "      <td>King David...</td>\n",
       "      <td>...</td>\n",
       "      <td>David the ...</td>\n",
       "      <td>Then David...</td>\n",
       "      <td>David the ...</td>\n",
       "      <td>Furthermor...</td>\n",
       "      <td>And David ...</td>\n",
       "      <td>To the who...</td>\n",
       "      <td>Furthermor...</td>\n",
       "      <td>And David ...</td>\n",
       "      <td>And king D...</td>\n",
       "      <td>And king D...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(Revelation, 1)</th>\n",
       "      <td>The Revela...</td>\n",
       "      <td>This book ...</td>\n",
       "      <td>Prologue                                    Th...</td>\n",
       "      <td>This is th...</td>\n",
       "      <td>The Revela...</td>\n",
       "      <td>Prologue                                    Th...</td>\n",
       "      <td>The Revela...</td>\n",
       "      <td>The Revela...</td>\n",
       "      <td>The Revela...</td>\n",
       "      <td>The revela...</td>\n",
       "      <td>...</td>\n",
       "      <td>This is th...</td>\n",
       "      <td>A revealin...</td>\n",
       "      <td>This is th...</td>\n",
       "      <td>The Revela...</td>\n",
       "      <td>The Revela...</td>\n",
       "      <td>This is th...</td>\n",
       "      <td>The Revela...</td>\n",
       "      <td>A revelati...</td>\n",
       "      <td>Apocalypse...</td>\n",
       "      <td>Revelation...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(Deuteronomy, 17)</th>\n",
       "      <td>Thou shalt...</td>\n",
       "      <td>Do not sac...</td>\n",
       "      <td>You must n...</td>\n",
       "      <td>Never offe...</td>\n",
       "      <td>Thou shalt...</td>\n",
       "      <td>You shall ...</td>\n",
       "      <td>Thou shalt...</td>\n",
       "      <td>Thou shalt...</td>\n",
       "      <td>You shall ...</td>\n",
       "      <td>You must n...</td>\n",
       "      <td>...</td>\n",
       "      <td>You shall ...</td>\n",
       "      <td>And dont s...</td>\n",
       "      <td>You shall ...</td>\n",
       "      <td>Thou shalt...</td>\n",
       "      <td>No ox or s...</td>\n",
       "      <td>You are no...</td>\n",
       "      <td>Thou shalt...</td>\n",
       "      <td>Thou dost ...</td>\n",
       "      <td>Thou shalt...</td>\n",
       "      <td>Thou shalt...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            American Standard Version  \\\n",
       "(Psalms, 52)                                            Why boaste...   \n",
       "(Habakkuk, 3)                                           A prayer o...   \n",
       "(1-Chronicles, 29)                                      And David ...   \n",
       "(Revelation, 1)                                         The Revela...   \n",
       "(Deuteronomy, 17)                                       Thou shalt...   \n",
       "\n",
       "                                                Good News Translation  \\\n",
       "(Psalms, 52)                                            Why do you...   \n",
       "(Habakkuk, 3)                                           This is a ...   \n",
       "(1-Chronicles, 29)                                      King David...   \n",
       "(Revelation, 1)                                         This book ...   \n",
       "(Deuteronomy, 17)                                       Do not sac...   \n",
       "\n",
       "                                      Holman Christian Standard Bible  \\\n",
       "(Psalms, 52)        God Judges the ProudFor the choir director A D...   \n",
       "(Habakkuk, 3)       Habakkuks Third Prayer                        ...   \n",
       "(1-Chronicles, 29)  Contributions for Building the Temple         ...   \n",
       "(Revelation, 1)     Prologue                                    Th...   \n",
       "(Deuteronomy, 17)                                       You must n...   \n",
       "\n",
       "                                               GOD'S WORD Translation  \\\n",
       "(Psalms, 52)                                            Why do you...   \n",
       "(Habakkuk, 3)                                           A prayer o...   \n",
       "(1-Chronicles, 29)                                      Then King ...   \n",
       "(Revelation, 1)                                         This is th...   \n",
       "(Deuteronomy, 17)                                       Never offe...   \n",
       "\n",
       "                                                   Jubilee Bible 2000  \\\n",
       "(Psalms, 52)                                            Why dost t...   \n",
       "(Habakkuk, 3)       A prayer of Habakkuk the prophet because of al...   \n",
       "(1-Chronicles, 29)                                      Furthermor...   \n",
       "(Revelation, 1)                                         The Revela...   \n",
       "(Deuteronomy, 17)                                       Thou shalt...   \n",
       "\n",
       "                                                 Lexham English Bible  \\\n",
       "(Psalms, 52)        For the music director A maskil of David When ...   \n",
       "(Habakkuk, 3)       The Prayer of Habakkuk                        ...   \n",
       "(1-Chronicles, 29)  Offerings for the Temple                      ...   \n",
       "(Revelation, 1)     Prologue                                    Th...   \n",
       "(Deuteronomy, 17)                                       You shall ...   \n",
       "\n",
       "                                                   King James Version  \\\n",
       "(Psalms, 52)                                            Why boaste...   \n",
       "(Habakkuk, 3)                                           A prayer o...   \n",
       "(1-Chronicles, 29)                                      Furthermor...   \n",
       "(Revelation, 1)                                         The Revela...   \n",
       "(Deuteronomy, 17)                                       Thou shalt...   \n",
       "\n",
       "                                          Douay-Rhiems Catholic Bible  \\\n",
       "(Psalms, 52)                                             Unto the ...   \n",
       "(Habakkuk, 3)                                           A PRAYER O...   \n",
       "(1-Chronicles, 29)                                      And king D...   \n",
       "(Revelation, 1)                                         The Revela...   \n",
       "(Deuteronomy, 17)                                       Thou shalt...   \n",
       "\n",
       "                                               New King James Version  \\\n",
       "(Psalms, 52)                                            To the Chi...   \n",
       "(Habakkuk, 3)                                           A prayer o...   \n",
       "(1-Chronicles, 29)                                      Furthermor...   \n",
       "(Revelation, 1)                                         The Revela...   \n",
       "(Deuteronomy, 17)                                       You shall ...   \n",
       "\n",
       "                                                 New Revised Standard  \\\n",
       "(Psalms, 52)                                            Why do you...   \n",
       "(Habakkuk, 3)                                           A prayer o...   \n",
       "(1-Chronicles, 29)                                      King David...   \n",
       "(Revelation, 1)                                         The revela...   \n",
       "(Deuteronomy, 17)                                       You must n...   \n",
       "\n",
       "                                          ...                          \\\n",
       "(Psalms, 52)                              ...                           \n",
       "(Habakkuk, 3)                             ...                           \n",
       "(1-Chronicles, 29)                        ...                           \n",
       "(Revelation, 1)                           ...                           \n",
       "(Deuteronomy, 17)                         ...                           \n",
       "\n",
       "                                                 Hebrew Names Version  \\\n",
       "(Psalms, 52)                                             Why do yo...   \n",
       "(Habakkuk, 3)                                           A prayer o...   \n",
       "(1-Chronicles, 29)                                      David the ...   \n",
       "(Revelation, 1)                                         This is th...   \n",
       "(Deuteronomy, 17)                                       You shall ...   \n",
       "\n",
       "                                                    The Message Bible  \\\n",
       "(Psalms, 52)                                            Why do you...   \n",
       "(Habakkuk, 3)                                           A prayer o...   \n",
       "(1-Chronicles, 29)                                      Then David...   \n",
       "(Revelation, 1)                                         A revealin...   \n",
       "(Deuteronomy, 17)                                       And dont s...   \n",
       "\n",
       "                                                  World English Bible  \\\n",
       "(Psalms, 52)                                             Why do yo...   \n",
       "(Habakkuk, 3)                                           A prayer o...   \n",
       "(1-Chronicles, 29)                                      David the ...   \n",
       "(Revelation, 1)                                         This is th...   \n",
       "(Deuteronomy, 17)                                       You shall ...   \n",
       "\n",
       "                                               Third Millennium Bible  \\\n",
       "(Psalms, 52)                                             Why boast...   \n",
       "(Habakkuk, 3)                                           A prayer o...   \n",
       "(1-Chronicles, 29)                                      Furthermor...   \n",
       "(Revelation, 1)                                         The Revela...   \n",
       "(Deuteronomy, 17)                                       Thou shalt...   \n",
       "\n",
       "                                           The Bible in Basic English  \\\n",
       "(Psalms, 52)                                            Purposing ...   \n",
       "(Habakkuk, 3)                                           A prayer o...   \n",
       "(1-Chronicles, 29)                                      And David ...   \n",
       "(Revelation, 1)                                         The Revela...   \n",
       "(Deuteronomy, 17)                                       No ox or s...   \n",
       "\n",
       "                                            The Complete Jewish Bible  \\\n",
       "(Psalms, 52)                                            For the le...   \n",
       "(Habakkuk, 3)                                           This is a ...   \n",
       "(1-Chronicles, 29)                                      To the who...   \n",
       "(Revelation, 1)                                         This is th...   \n",
       "(Deuteronomy, 17)                                       You are no...   \n",
       "\n",
       "                                                    The Webster Bible  \\\n",
       "(Psalms, 52)                                            To the chi...   \n",
       "(Habakkuk, 3)                                           A prayer o...   \n",
       "(1-Chronicles, 29)                                      Furthermor...   \n",
       "(Revelation, 1)                                         The Revela...   \n",
       "(Deuteronomy, 17)                                       Thou shalt...   \n",
       "\n",
       "                                          Young's Literal Translation  \\\n",
       "(Psalms, 52)                                            To the Ove...   \n",
       "(Habakkuk, 3)                                           A prayer o...   \n",
       "(1-Chronicles, 29)                                      And David ...   \n",
       "(Revelation, 1)                                         A revelati...   \n",
       "(Deuteronomy, 17)                                       Thou dost ...   \n",
       "\n",
       "                                                             Wycliffe  \\\n",
       "(Psalms, 52)                                            To victory...   \n",
       "(Habakkuk, 3)                                           The prayer...   \n",
       "(1-Chronicles, 29)                                      And king D...   \n",
       "(Revelation, 1)                                         Apocalypse...   \n",
       "(Deuteronomy, 17)                                       Thou shalt...   \n",
       "\n",
       "                                                The Darby Translation  \n",
       "(Psalms, 52)                                            To the chi...  \n",
       "(Habakkuk, 3)                                           A Prayer o...  \n",
       "(1-Chronicles, 29)                                      And king D...  \n",
       "(Revelation, 1)                                         Revelation...  \n",
       "(Deuteronomy, 17)                                       Thou shalt...  \n",
       "\n",
       "[5 rows x 24 columns]"
      ]
     },
     "execution_count": 463,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bibles_metadata_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>American Standard Version</th>\n",
       "      <th>Good News Translation</th>\n",
       "      <th>English Standard Version</th>\n",
       "      <th>Holman Christian Standard Bible</th>\n",
       "      <th>GOD'S WORD Translation</th>\n",
       "      <th>Jubilee Bible 2000</th>\n",
       "      <th>Lexham English Bible</th>\n",
       "      <th>King James Version</th>\n",
       "      <th>Douay-Rhiems Catholic Bible</th>\n",
       "      <th>New King James Version</th>\n",
       "      <th>...</th>\n",
       "      <th>The Complete Jewish Bible</th>\n",
       "      <th>The Bible in Basic English</th>\n",
       "      <th>New Century Version</th>\n",
       "      <th>New International Reader's Version</th>\n",
       "      <th>World English Bible</th>\n",
       "      <th>Young's Literal Translation</th>\n",
       "      <th>Third Millennium Bible</th>\n",
       "      <th>The Webster Bible</th>\n",
       "      <th>Wycliffe</th>\n",
       "      <th>The Darby Translation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Paul calle...</td>\n",
       "      <td>From Paul ...</td>\n",
       "      <td>Greeting                                    Pa...</td>\n",
       "      <td>Greeting                                    Pa...</td>\n",
       "      <td>From Paul ...</td>\n",
       "      <td>Paul calle...</td>\n",
       "      <td>Greeting                                    Pa...</td>\n",
       "      <td>Paul called to be an apostle of Jesus Christ t...</td>\n",
       "      <td>Paul calle...</td>\n",
       "      <td>Paul calle...</td>\n",
       "      <td>...</td>\n",
       "      <td>From Shaul...</td>\n",
       "      <td>Paul an Ap...</td>\n",
       "      <td>From Paul ...</td>\n",
       "      <td>I Paul am ...</td>\n",
       "      <td>Paul calle...</td>\n",
       "      <td>Paul a cal...</td>\n",
       "      <td>Paul calle...</td>\n",
       "      <td>Paul calle...</td>\n",
       "      <td>Paul calle...</td>\n",
       "      <td>Paul a cal...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>And I bret...</td>\n",
       "      <td>When I cam...</td>\n",
       "      <td>Proclaiming Christ Crucified                  ...</td>\n",
       "      <td>Pauls Proclamation                            ...</td>\n",
       "      <td>Brothers a...</td>\n",
       "      <td>And I brot...</td>\n",
       "      <td>Pauls Approach to Ministry in Corinth         ...</td>\n",
       "      <td>And I bret...</td>\n",
       "      <td>And I bret...</td>\n",
       "      <td>And I bret...</td>\n",
       "      <td>...</td>\n",
       "      <td>As for me ...</td>\n",
       "      <td>And when I...</td>\n",
       "      <td>Dear broth...</td>\n",
       "      <td>Brothers a...</td>\n",
       "      <td>When I cam...</td>\n",
       "      <td>And I havi...</td>\n",
       "      <td>And I bret...</td>\n",
       "      <td>And I bret...</td>\n",
       "      <td>And I bret...</td>\n",
       "      <td>And I when...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>And I bret...</td>\n",
       "      <td>As a matte...</td>\n",
       "      <td>Divisions in the Church                       ...</td>\n",
       "      <td>The Problem of Immaturity                     ...</td>\n",
       "      <td>Brothers a...</td>\n",
       "      <td>And I brot...</td>\n",
       "      <td>Divisiveness and Immaturity                   ...</td>\n",
       "      <td>And I brethren could not speak  unto you as un...</td>\n",
       "      <td>And I bret...</td>\n",
       "      <td>And I bret...</td>\n",
       "      <td>...</td>\n",
       "      <td>As for me ...</td>\n",
       "      <td>And the te...</td>\n",
       "      <td>Brothers a...</td>\n",
       "      <td>Taking Sides in the Church                    ...</td>\n",
       "      <td>Brothers I...</td>\n",
       "      <td>And I bret...</td>\n",
       "      <td>And I bret...</td>\n",
       "      <td>And I bret...</td>\n",
       "      <td>And I bret...</td>\n",
       "      <td>And I bret...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Let a man ...</td>\n",
       "      <td>You should...</td>\n",
       "      <td>The Ministry of Apostles                      ...</td>\n",
       "      <td>The Faithful Manager                          ...</td>\n",
       "      <td>People sho...</td>\n",
       "      <td>Let us rec...</td>\n",
       "      <td>Christs Servant Gods Steward                  ...</td>\n",
       "      <td>Let  a man so account  of us as of the ministe...</td>\n",
       "      <td>Let a man ...</td>\n",
       "      <td>Let a man ...</td>\n",
       "      <td>...</td>\n",
       "      <td>So you sho...</td>\n",
       "      <td>Let us be ...</td>\n",
       "      <td>People sho...</td>\n",
       "      <td>Apostles of Christ                            ...</td>\n",
       "      <td>So let a m...</td>\n",
       "      <td>Let a man ...</td>\n",
       "      <td>Let a man ...</td>\n",
       "      <td>Let a man ...</td>\n",
       "      <td>So a man g...</td>\n",
       "      <td>Let a man ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>It is actu...</td>\n",
       "      <td>Now it is ...</td>\n",
       "      <td>Sexual Immorality Defiles the Church          ...</td>\n",
       "      <td>Immoral Church Members                        ...</td>\n",
       "      <td>Your own m...</td>\n",
       "      <td>It is repo...</td>\n",
       "      <td>Immoral Behavior and Church Discipline        ...</td>\n",
       "      <td>It is repo...</td>\n",
       "      <td>It is abso...</td>\n",
       "      <td>It is actu...</td>\n",
       "      <td>...</td>\n",
       "      <td>It is actu...</td>\n",
       "      <td>It is said...</td>\n",
       "      <td>It is actu...</td>\n",
       "      <td>Throw the Evil Person Out                     ...</td>\n",
       "      <td>It is actu...</td>\n",
       "      <td>Whoredom i...</td>\n",
       "      <td>It is repo...</td>\n",
       "      <td>It is repo...</td>\n",
       "      <td>Yet all ma...</td>\n",
       "      <td>It is univ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                           American Standard Version  \\\n",
       "0                                      Paul calle...   \n",
       "1                                      And I bret...   \n",
       "2                                      And I bret...   \n",
       "3                                      Let a man ...   \n",
       "4                                      It is actu...   \n",
       "\n",
       "                               Good News Translation  \\\n",
       "0                                      From Paul ...   \n",
       "1                                      When I cam...   \n",
       "2                                      As a matte...   \n",
       "3                                      You should...   \n",
       "4                                      Now it is ...   \n",
       "\n",
       "                            English Standard Version  \\\n",
       "0  Greeting                                    Pa...   \n",
       "1  Proclaiming Christ Crucified                  ...   \n",
       "2  Divisions in the Church                       ...   \n",
       "3  The Ministry of Apostles                      ...   \n",
       "4  Sexual Immorality Defiles the Church          ...   \n",
       "\n",
       "                     Holman Christian Standard Bible  \\\n",
       "0  Greeting                                    Pa...   \n",
       "1  Pauls Proclamation                            ...   \n",
       "2  The Problem of Immaturity                     ...   \n",
       "3  The Faithful Manager                          ...   \n",
       "4  Immoral Church Members                        ...   \n",
       "\n",
       "                              GOD'S WORD Translation  \\\n",
       "0                                      From Paul ...   \n",
       "1                                      Brothers a...   \n",
       "2                                      Brothers a...   \n",
       "3                                      People sho...   \n",
       "4                                      Your own m...   \n",
       "\n",
       "                                  Jubilee Bible 2000  \\\n",
       "0                                      Paul calle...   \n",
       "1                                      And I brot...   \n",
       "2                                      And I brot...   \n",
       "3                                      Let us rec...   \n",
       "4                                      It is repo...   \n",
       "\n",
       "                                Lexham English Bible  \\\n",
       "0  Greeting                                    Pa...   \n",
       "1  Pauls Approach to Ministry in Corinth         ...   \n",
       "2  Divisiveness and Immaturity                   ...   \n",
       "3  Christs Servant Gods Steward                  ...   \n",
       "4  Immoral Behavior and Church Discipline        ...   \n",
       "\n",
       "                                  King James Version  \\\n",
       "0  Paul called to be an apostle of Jesus Christ t...   \n",
       "1                                      And I bret...   \n",
       "2  And I brethren could not speak  unto you as un...   \n",
       "3  Let  a man so account  of us as of the ministe...   \n",
       "4                                      It is repo...   \n",
       "\n",
       "                         Douay-Rhiems Catholic Bible  \\\n",
       "0                                      Paul calle...   \n",
       "1                                      And I bret...   \n",
       "2                                      And I bret...   \n",
       "3                                      Let a man ...   \n",
       "4                                      It is abso...   \n",
       "\n",
       "                              New King James Version  \\\n",
       "0                                      Paul calle...   \n",
       "1                                      And I bret...   \n",
       "2                                      And I bret...   \n",
       "3                                      Let a man ...   \n",
       "4                                      It is actu...   \n",
       "\n",
       "                         ...                          \\\n",
       "0                        ...                           \n",
       "1                        ...                           \n",
       "2                        ...                           \n",
       "3                        ...                           \n",
       "4                        ...                           \n",
       "\n",
       "                           The Complete Jewish Bible  \\\n",
       "0                                      From Shaul...   \n",
       "1                                      As for me ...   \n",
       "2                                      As for me ...   \n",
       "3                                      So you sho...   \n",
       "4                                      It is actu...   \n",
       "\n",
       "                          The Bible in Basic English  \\\n",
       "0                                      Paul an Ap...   \n",
       "1                                      And when I...   \n",
       "2                                      And the te...   \n",
       "3                                      Let us be ...   \n",
       "4                                      It is said...   \n",
       "\n",
       "                                 New Century Version  \\\n",
       "0                                      From Paul ...   \n",
       "1                                      Dear broth...   \n",
       "2                                      Brothers a...   \n",
       "3                                      People sho...   \n",
       "4                                      It is actu...   \n",
       "\n",
       "                  New International Reader's Version  \\\n",
       "0                                      I Paul am ...   \n",
       "1                                      Brothers a...   \n",
       "2  Taking Sides in the Church                    ...   \n",
       "3  Apostles of Christ                            ...   \n",
       "4  Throw the Evil Person Out                     ...   \n",
       "\n",
       "                                 World English Bible  \\\n",
       "0                                      Paul calle...   \n",
       "1                                      When I cam...   \n",
       "2                                      Brothers I...   \n",
       "3                                      So let a m...   \n",
       "4                                      It is actu...   \n",
       "\n",
       "                         Young's Literal Translation  \\\n",
       "0                                      Paul a cal...   \n",
       "1                                      And I havi...   \n",
       "2                                      And I bret...   \n",
       "3                                      Let a man ...   \n",
       "4                                      Whoredom i...   \n",
       "\n",
       "                              Third Millennium Bible  \\\n",
       "0                                      Paul calle...   \n",
       "1                                      And I bret...   \n",
       "2                                      And I bret...   \n",
       "3                                      Let a man ...   \n",
       "4                                      It is repo...   \n",
       "\n",
       "                                   The Webster Bible  \\\n",
       "0                                      Paul calle...   \n",
       "1                                      And I bret...   \n",
       "2                                      And I bret...   \n",
       "3                                      Let a man ...   \n",
       "4                                      It is repo...   \n",
       "\n",
       "                                            Wycliffe  \\\n",
       "0                                      Paul calle...   \n",
       "1                                      And I bret...   \n",
       "2                                      And I bret...   \n",
       "3                                      So a man g...   \n",
       "4                                      Yet all ma...   \n",
       "\n",
       "                               The Darby Translation  \n",
       "0                                      Paul a cal...  \n",
       "1                                      And I when...  \n",
       "2                                      And I bret...  \n",
       "3                                      Let a man ...  \n",
       "4                                      It is univ...  \n",
       "\n",
       "[5 rows x 27 columns]"
      ]
     },
     "execution_count": 235,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bibles_df.head()   \n",
    "#yaaaaaaas (ideally the indices would be labels buuuut...fuqdat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 392,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1189"
      ]
     },
     "execution_count": 392,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(bibles_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cleaned_bibles_df = bibles_df.drop(\n",
    "    'New International Version', axis=1).drop(\n",
    "    'English Standard Version', axis=1).drop(\n",
    "    'New American Standard Bible', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['New International Version', 'Hebrew Names Version', 'Good News Translation', \"GOD'S WORD Translation\", 'King James Version', 'The Darby Translation', 'The Webster Bible', 'Wycliffe', 'The Bible in Basic English', 'World English Bible', 'Douay-Rhiems Catholic Bible', 'Lexham English Bible', 'New Living Translation', 'Revised Standard Version', 'New Century Version', \"New International Reader's Version\", 'Jubilee Bible 2000', 'English Standard Version', 'New American Standard Bible', 'American Standard Version', 'Holman Christian Standard Bible', 'New Revised Standard', \"Young's Literal Translation\", 'The Complete Jewish Bible', 'The Message Bible', 'New King James Version', 'Third Millennium Bible']\n"
     ]
    }
   ],
   "source": [
    "print versions.keys()\n",
    "# 'New International Version' == fucked up\n",
    "# 'Hebrew Names Version'\n",
    "# 'Good News Translation'\n",
    "# \"GOD'S WORD Translation\"\n",
    "# 'King James Version'\n",
    "# 'The Darby Translation'\n",
    "# 'The Webster Bible'\n",
    "# 'Wycliffe'\n",
    "# 'The Bible in Basic English'\n",
    "# 'World English Bible'\n",
    "# 'Douay-Rhiems Catholic Bible'\n",
    "# 'Lexham English Bible' == lil bit fucked; 'references', 'footnotes'\n",
    "# 'New Living Translation'\n",
    "# 'Revised Standard Version'\n",
    "# 'New Century Version'\n",
    "# \"New International Reader's Version\"\n",
    "# 'Jubilee Bible 2000'\n",
    "# 'English Standard Version' == fucked\n",
    "# 'New American Standard Bible' == fucked\n",
    "# 'American Standard Version'\n",
    "# 'Holman Christian Standard Bible' ==lil bit fucked; 'references', 'footnotes'\n",
    "# 'New Revised Standard'==lil bit fucked; 'references', 'footnotes'\n",
    "# \"Young's Literal Translation\"\n",
    "# 'The Complete Jewish Bible'\n",
    "# 'The Message Bible'\n",
    "# 'New King James Version'\n",
    "# 'Third Millennium Bible'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# for name in versions.keys(): \n",
    "#     print name\n",
    "#     print bibles_df[name][22]\n",
    "#     print '\\n\\n\\n'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#2. CountVectorize that shit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'NN': 'noun, singular or mass---door',\n",
    "'NNS': 'noun plural---doors',\n",
    "'NNP': 'proper noun, singular---John',\n",
    "'NNPS': 'proper noun, plural---Vikings',"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.\n",
    "- filter out all but NN and NNS\n",
    "- filter out all but NNP and NNPS\n",
    "- then do topic modeling based on these.\n",
    "\n",
    "\n",
    "2. \n",
    "- see diana's notebook for lda viz\n",
    "\n",
    "3.\n",
    "- clustering w/ jaccard distance\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 470,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "archaic_stopwords = nltk.corpus.stopwords.words('english') + [u'shall', u'shant', u'ye', \n",
    "                                                              u'thy', u'thou', u'thee', \n",
    "                                                              u'thine', u'said', u'hast', \n",
    "                                                              u'hath', u'unto', u'upon',\n",
    "                                                              u'references', u'footnotes',\n",
    "                                                              u'came', u'come', u'went',\n",
    "                                                              u'heb', u'made', u'make',\n",
    "                                                              u'doth', u'saith']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "##single bible from gutenberg\n",
    "vectorizer = CountVectorizer(stop_words=archaic_stopwords, \n",
    "                             token_pattern='[A-Za-z]+', min_df=2)\n",
    "vecs_bible = vectorizer.fit_transform(docs_bible)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####Here's w/ all the bibles:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "version_names = cleaned_bibles_df.columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24"
      ]
     },
     "execution_count": 321,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(version_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import timeit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('who', 'WP')]"
      ]
     },
     "execution_count": 368,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.tag import pos_tag\n",
    "from nltk.tokenize import word_tokenize\n",
    "words = word_tokenize(\"Who's going to that thing today?\")\n",
    "pos_tag(['who'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('apple', u'NN'),\n",
       " ('orange', u'NN'),\n",
       " ('banana', u'NN'),\n",
       " ('cynthia', u'VB'),\n",
       " ('one', u'CD'),\n",
       " ('cynthia', u'VBZ'),\n",
       " ('two', u'CD')]"
      ]
     },
     "execution_count": 372,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blob = TextBlob('apple orange banana, cynthia one, cynthia two')\n",
    "blob.tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|██▎       | 276/1189 [09:42<32:07,  2.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "American Standard Version\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-373-44d58004772e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mcorpus\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mdoc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcleaned_bibles_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mword\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpos\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mTextBlob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtags\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpos\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34mu'NN'\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mpos\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34mu'NNS'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m                 \u001b[0mdoc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/Ben/anaconda/anaconda/lib/python2.7/site-packages/textblob/decorators.pyc\u001b[0m in \u001b[0;36m__get__\u001b[0;34m(self, obj, cls)\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m         \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__dict__\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/Ben/anaconda/anaconda/lib/python2.7/site-packages/textblob/blob.pyc\u001b[0m in \u001b[0;36mpos_tags\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    443\u001b[0m         \"\"\"\n\u001b[1;32m    444\u001b[0m         return [(Word(word, pos_tag=t), unicode(t))\n\u001b[0;32m--> 445\u001b[0;31m                 \u001b[0;32mfor\u001b[0m \u001b[0mword\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpos_tagger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtag\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    446\u001b[0m                 if not PUNCTUATION_REGEX.match(unicode(t))]\n\u001b[1;32m    447\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/Ben/anaconda/anaconda/lib/python2.7/site-packages/textblob/decorators.pyc\u001b[0m in \u001b[0;36mdecorated\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     33\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdecorated\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mLookupError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m             \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/Ben/anaconda/anaconda/lib/python2.7/site-packages/textblob/en/taggers.pyc\u001b[0m in \u001b[0;36mtag\u001b[0;34m(self, text, tokenize)\u001b[0m\n\u001b[1;32m     32\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtokenize\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m             \u001b[0mtext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword_tokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m         \u001b[0mtagged\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtag\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpos_tag\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtagged\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/Ben/anaconda/anaconda/lib/python2.7/site-packages/nltk/tag/__init__.pyc\u001b[0m in \u001b[0;36mpos_tag\u001b[0;34m(tokens, tagset)\u001b[0m\n\u001b[1;32m    108\u001b[0m     \u001b[0;34m:\u001b[0m\u001b[0mrtype\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m     \"\"\"\n\u001b[0;32m--> 110\u001b[0;31m     \u001b[0mtagger\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPerceptronTagger\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    111\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0m_pos_tag\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokens\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtagset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtagger\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/Ben/anaconda/anaconda/lib/python2.7/site-packages/nltk/tag/perceptron.pyc\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, load)\u001b[0m\n\u001b[1;32m    140\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mload\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m             \u001b[0mAP_MODEL_LOC\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'taggers/averaged_perceptron_tagger/'\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mPICKLE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 142\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mAP_MODEL_LOC\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    143\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mtag\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtokens\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/Ben/anaconda/anaconda/lib/python2.7/site-packages/nltk/tag/perceptron.pyc\u001b[0m in \u001b[0;36mload\u001b[0;34m(self, loc)\u001b[0m\n\u001b[1;32m    209\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfin\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 211\u001b[0;31m             \u001b[0mw_td_c\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfin\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    212\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtagdict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mw_td_c\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/Ben/anaconda/anaconda/lib/python2.7/pickle.pyc\u001b[0m in \u001b[0;36mload\u001b[0;34m(file)\u001b[0m\n\u001b[1;32m   1382\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1383\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1384\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mUnpickler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1385\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1386\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mloads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/Ben/anaconda/anaconda/lib/python2.7/pickle.pyc\u001b[0m in \u001b[0;36mload\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    862\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    863\u001b[0m                 \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 864\u001b[0;31m                 \u001b[0mdispatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    865\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0m_Stop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstopinst\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    866\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mstopinst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/Ben/anaconda/anaconda/lib/python2.7/pickle.pyc\u001b[0m in \u001b[0;36mload_setitems\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1209\u001b[0m         \u001b[0mmark\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmarker\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1210\u001b[0m         \u001b[0mdict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstack\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmark\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1211\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmark\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1212\u001b[0m             \u001b[0mdict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstack\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1213\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "bibles_nouns = {}\n",
    "#bibles_proper_nouns = {}\n",
    "for name in version_names:\n",
    "    print name\n",
    "    corpus = []\n",
    "    for doc in tqdm(cleaned_bibles_df[name]):\n",
    "        for word, pos in TextBlob(doc).tags:\n",
    "            if pos != u'NN' and pos != u'NNS':\n",
    "                doc.replace(word, '')\n",
    "        corpus.append(doc)\n",
    "    bibles_nouns[name] = corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 471,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 1/24 [00:00<00:03,  6.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "American Standard Version\n",
      "Good News Translation"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  8%|▊         | 2/24 [00:00<00:03,  7.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Holman Christian Standard Bible"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 12%|█▎        | 3/24 [00:00<00:03,  6.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "GOD'S WORD Translation"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 17%|█▋        | 4/24 [00:00<00:02,  6.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Jubilee Bible 2000"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 21%|██        | 5/24 [00:00<00:02,  6.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Lexham English Bible"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 25%|██▌       | 6/24 [00:00<00:02,  6.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "King James Version"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 29%|██▉       | 7/24 [00:01<00:02,  6.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Douay-Rhiems Catholic Bible"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 33%|███▎      | 8/24 [00:01<00:02,  6.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "New King James Version"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 38%|███▊      | 9/24 [00:01<00:02,  6.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "New Living Translation"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 42%|████▏     | 10/24 [00:01<00:02,  6.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The Message Bible"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 46%|████▌     | 11/24 [00:01<00:01,  7.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Hebrew Names Version"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 50%|█████     | 12/24 [00:01<00:01,  7.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "New Revised Standard"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 54%|█████▍    | 13/24 [00:01<00:01,  7.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Revised Standard Version"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 58%|█████▊    | 14/24 [00:02<00:01,  7.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The Complete Jewish Bible"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 62%|██████▎   | 15/24 [00:02<00:01,  7.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The Bible in Basic English"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 67%|██████▋   | 16/24 [00:02<00:01,  7.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "New Century Version"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 71%|███████   | 17/24 [00:02<00:00,  7.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "New International Reader's Version"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 75%|███████▌  | 18/24 [00:02<00:00,  6.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "World English Bible"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 79%|███████▉  | 19/24 [00:02<00:00,  7.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Young's Literal Translation"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 83%|████████▎ | 20/24 [00:02<00:00,  7.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Third Millennium Bible"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 88%|████████▊ | 21/24 [00:02<00:00,  7.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The Webster Bible"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 92%|█████████▏| 22/24 [00:03<00:00,  7.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Wycliffe"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 96%|█████████▌| 23/24 [00:03<00:00,  6.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The Darby Translation"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                               "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "#####genesis_all_bibles (scrapedstuff)######\n",
    "\n",
    "cv_genesis = {}\n",
    "for name in tqdm(version_names):\n",
    "    vectorizer = CountVectorizer(stop_words=archaic_stopwords, \n",
    "                             token_pattern='[A-Za-z]+', min_df=2)\n",
    "    single_bible_corpus = genesis_df[name]\n",
    "    print name\n",
    "    vectorized = vectorizer.fit_transform(single_bible_corpus)\n",
    "    cv_genesis[name] = (vectorizer, vectorized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 424,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 1/24 [00:02<01:02,  2.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "American Standard Version\n",
      "Good News Translation"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  8%|▊         | 2/24 [00:05<00:59,  2.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Holman Christian Standard Bible"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 12%|█▎        | 3/24 [00:08<00:59,  2.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "GOD'S WORD Translation"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 17%|█▋        | 4/24 [00:11<00:55,  2.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Jubilee Bible 2000"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 21%|██        | 5/24 [00:14<00:53,  2.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Lexham English Bible"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 25%|██▌       | 6/24 [00:18<00:57,  3.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "King James Version"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 29%|██▉       | 7/24 [00:21<00:54,  3.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Douay-Rhiems Catholic Bible"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 33%|███▎      | 8/24 [00:24<00:49,  3.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "New King James Version"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 38%|███▊      | 9/24 [00:27<00:45,  3.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "New Living Translation"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 42%|████▏     | 10/24 [00:30<00:42,  3.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The Message Bible"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 46%|████▌     | 11/24 [00:33<00:39,  3.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Hebrew Names Version"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 50%|█████     | 12/24 [00:35<00:34,  2.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "New Revised Standard"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 54%|█████▍    | 13/24 [00:38<00:31,  2.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Revised Standard Version"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 58%|█████▊    | 14/24 [00:41<00:28,  2.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The Complete Jewish Bible"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 62%|██████▎   | 15/24 [00:44<00:25,  2.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The Bible in Basic English"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 67%|██████▋   | 16/24 [00:47<00:23,  2.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "New Century Version"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 71%|███████   | 17/24 [00:49<00:19,  2.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "New International Reader's Version"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 75%|███████▌  | 18/24 [00:52<00:17,  2.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "World English Bible"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 79%|███████▉  | 19/24 [00:55<00:14,  2.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Young's Literal Translation"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 83%|████████▎ | 20/24 [00:58<00:10,  2.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Third Millennium Bible"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 88%|████████▊ | 21/24 [01:00<00:08,  2.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The Webster Bible"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 92%|█████████▏| 22/24 [01:03<00:05,  2.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Wycliffe"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 96%|█████████▌| 23/24 [01:08<00:03,  3.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The Darby Translation"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                               "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "######allathabibles (scrapedstuff)######\n",
    "\n",
    "count_vectorized_bibles = {}\n",
    "for name in tqdm(version_names):\n",
    "    vectorizer = CountVectorizer(stop_words=archaic_stopwords, \n",
    "                             token_pattern='[A-Za-z]+', min_df=2)\n",
    "    single_bible_corpus = cleaned_bibles_df[name]\n",
    "    print name\n",
    "    vectorized = vectorizer.fit_transform(single_bible_corpus)\n",
    "    count_vectorized_bibles[name] = (vectorizer, vectorized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 416,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ylt_vectorizer = CountVectorizer(stop_words=archaic_stopwords, \n",
    "                             token_pattern='[A-Za-z]+', min_df=2)\n",
    "ylt_corpus = cleaned_bibles_df['Young\\'s Literal Translation']\n",
    "ylt_vectorized = ylt_vectorizer.fit_transform(ylt_corpus)\n",
    "count_vectorized_bibles['Young\\'s Literal Translation'] = (ylt_vectorizer, ylt_vectorized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# with open('count_vectorized_bibles.pkl', 'w') as picklefile:\n",
    "#     pickle.dump(count_vectorized_bibles, picklefile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<1189x10364 sparse matrix of type '<type 'numpy.int64'>'\n",
       "\twith 226272 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 265,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_vectorized_bibles['New International Version']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "counts_dfs = {}\n",
    "for name, values in count_vectorized_bibles.items():\n",
    "    vecs_array = values[1].toarray()\n",
    "    counts_df = pd.DataFrame(vecs_array, columns=values[0].get_feature_names())\n",
    "    counts_dfs[name] = counts_df\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#First Really Interesting Thing: \n",
    "interesting differences:!!\n",
    "\n",
    "linguistic homologies: top words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hebrew Names Version\n",
      "         word  freq\n",
      "4113     lord  7814\n",
      "2971      god  4277\n",
      "8004  yisrael  2542\n",
      "6522      son  2348\n",
      "4228      man  2322\n",
      "\n",
      "\n",
      "Good News Translation\n",
      "        word  freq\n",
      "4235    lord  6423\n",
      "5143  people  5014\n",
      "2994     god  4432\n",
      "1578   cross  3549\n",
      "4917     one  2789\n",
      "\n",
      "\n",
      "GOD'S WORD Translation\n",
      "        word  freq\n",
      "4479    lord  6963\n",
      "5429  people  4850\n",
      "3130     god  4110\n",
      "5179     one  2360\n",
      "4208    king  2264\n",
      "\n",
      "\n",
      "King James Version\n",
      "        word  freq\n",
      "4975    lord  7649\n",
      "3476     god  4160\n",
      "5109     man  2624\n",
      "4307  israel  2476\n",
      "7690     son  2341\n",
      "\n",
      "\n",
      "The Darby Translation\n",
      "         word  freq\n",
      "4797  jehovah  6800\n",
      "3834      god  4246\n",
      "7791      see  2957\n",
      "6182      one  2649\n",
      "4706   israel  2599\n",
      "\n",
      "\n",
      "The Webster Bible\n",
      "        word  freq\n",
      "4315    lord  7830\n",
      "3062     god  4410\n",
      "4430     man  2618\n",
      "3748  israel  2566\n",
      "6717     son  2358\n",
      "\n",
      "\n",
      "Wycliffe\n",
      "        word   freq\n",
      "4937    lord  13815\n",
      "3528     god   7366\n",
      "5199     men   5422\n",
      "8164  things   4788\n",
      "5059     man   4681\n",
      "\n",
      "\n",
      "The Bible in Basic English\n",
      "      word  freq\n",
      "2231  lord  7558\n",
      "2987   put  4508\n",
      "1456  give  4131\n",
      "1470   god  4123\n",
      "2164   let  3073\n",
      "\n",
      "\n",
      "New King James Version\n",
      "        word  freq\n",
      "4670    lord  7801\n",
      "3305     god  4452\n",
      "5420     one  2644\n",
      "4066  israel  2569\n",
      "7302     son  2389\n",
      "\n",
      "\n",
      "Douay-Rhiems Catholic Bible\n",
      "        word  freq\n",
      "4357    lord  7712\n",
      "3212     god  4378\n",
      "4464     man  2474\n",
      "3868  israel  2426\n",
      "6826     son  2281\n",
      "\n",
      "\n",
      "Lexham English Bible\n",
      "           word   freq\n",
      "5349  literally  11263\n",
      "9963     yahweh   7005\n",
      "3856        god   4210\n",
      "6224        one   3938\n",
      "8754   supplied   2761\n",
      "\n",
      "\n",
      "New Living Translation\n",
      "        word  freq\n",
      "5299    lord  7826\n",
      "3740     god  4453\n",
      "6462  people  3885\n",
      "4110  hebrew  2573\n",
      "4969    king  2414\n",
      "\n",
      "\n",
      "Revised Standard Version\n",
      "        word  freq\n",
      "4776    lord  7792\n",
      "3400     god  4331\n",
      "4194  israel  2558\n",
      "5510     one  2558\n",
      "5759  people  2520\n",
      "\n",
      "\n",
      "New Century Version\n",
      "        word  freq\n",
      "3455    lord  7465\n",
      "4223  people  6729\n",
      "2343     god  5214\n",
      "3216    king  2822\n",
      "4048     one  2536\n",
      "\n",
      "\n",
      "New International Reader's Version\n",
      "        word  freq\n",
      "3221    lord  7325\n",
      "3939  people  6569\n",
      "2180     god  4508\n",
      "3788     one  2914\n",
      "2980    king  2845\n",
      "\n",
      "\n",
      "Jubilee Bible 2000\n",
      "        word  freq\n",
      "4344    lord  7801\n",
      "3093     god  4455\n",
      "6706    sons  2690\n",
      "5023     one  2610\n",
      "3791  israel  2573\n",
      "\n",
      "\n",
      "American Standard Version\n",
      "         word  freq\n",
      "3906  jehovah  6770\n",
      "3098      god  4045\n",
      "3814   israel  2566\n",
      "4505      man  2525\n",
      "6830      son  2337\n",
      "\n",
      "\n",
      "Holman Christian Standard Bible\n",
      "      word  freq\n",
      "6150  lord  6708\n",
      "4180   god  4128\n",
      "6080   lit  3245\n",
      "7104   one  3116\n",
      "5726  king  2429\n",
      "\n",
      "\n",
      "New Revised Standard\n",
      "        word  freq\n",
      "5076    lord  7814\n",
      "3612     god  4402\n",
      "5844     one  3127\n",
      "6111  people  2354\n",
      "4746    king  2333\n",
      "\n",
      "\n",
      "Young's Literal Translation\n",
      "         word  freq\n",
      "3730  jehovah  6770\n",
      "2959      god  4079\n",
      "1990     doth  3480\n",
      "4839      one  2810\n",
      "6585     sons  2783\n",
      "\n",
      "\n",
      "The Complete Jewish Bible\n",
      "        word  freq\n",
      "141   adonai  6572\n",
      "3741     god  3920\n",
      "6246  people  3448\n",
      "4665  israel  2525\n",
      "5956     one  2508\n",
      "\n",
      "\n",
      "The Message Bible\n",
      "        word  freq\n",
      "4609     god  9448\n",
      "7809  people  2724\n",
      "7474     one  2378\n",
      "6102    king  2224\n",
      "3164    dont  2180\n",
      "\n",
      "\n",
      "World English Bible\n",
      "        word  freq\n",
      "8033  yahweh  6695\n",
      "3061     god  4003\n",
      "3764  israel  2573\n",
      "6729     son  2348\n",
      "4429     man  2328\n",
      "\n",
      "\n",
      "Third Millennium Bible\n",
      "        word  freq\n",
      "4289    lord  7834\n",
      "3054     god  4452\n",
      "4397     man  2607\n",
      "3727  israel  2564\n",
      "6646     son  2375\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Ben/anaconda/anaconda/lib/python2.7/site-packages/IPython/kernel/__main__.py:5: FutureWarning: sort(columns=....) is deprecated, use sort_values(by=.....)\n"
     ]
    }
   ],
   "source": [
    "#most popular words\n",
    "for name, df in counts_dfs.items():\n",
    "    freq = df.sum().reset_index()\n",
    "    freq.columns = ['word', 'freq']\n",
    "    freq = freq.sort(columns='freq', ascending=False)\n",
    "    print name\n",
    "    print freq.head()\n",
    "    print '\\n'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "vecs_bible_array = vecs_bible.toarray()\n",
    "counts_df = pd.DataFrame(vecs_bible_array, columns=vectorizer.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>aaron</th>\n",
       "      <th>aaronand</th>\n",
       "      <th>aaronites</th>\n",
       "      <th>aaronnumbered</th>\n",
       "      <th>aaronthe</th>\n",
       "      <th>abarim</th>\n",
       "      <th>abase</th>\n",
       "      <th>abased</th>\n",
       "      <th>abated</th>\n",
       "      <th>abba</th>\n",
       "      <th>...</th>\n",
       "      <th>zobah</th>\n",
       "      <th>zohar</th>\n",
       "      <th>zophah</th>\n",
       "      <th>zophar</th>\n",
       "      <th>zorah</th>\n",
       "      <th>zorobabel</th>\n",
       "      <th>zuar</th>\n",
       "      <th>zuph</th>\n",
       "      <th>zur</th>\n",
       "      <th>zurishaddai</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 13400 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   aaron  aaronand  aaronites  aaronnumbered  aaronthe  abarim  abase  abased  \\\n",
       "0      0         0          0              0         0       0      0       0   \n",
       "\n",
       "   abated  abba     ...       zobah  zohar  zophah  zophar  zorah  zorobabel  \\\n",
       "0       0     0     ...           0      0       0       0      0          0   \n",
       "\n",
       "   zuar  zuph  zur  zurishaddai  \n",
       "0     0     0    0            0  \n",
       "\n",
       "[1 rows x 13400 columns]"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counts_df[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Ben/anaconda/anaconda/lib/python2.7/site-packages/IPython/kernel/__main__.py:4: FutureWarning: sort(columns=....) is deprecated, use sort_values(by=.....)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>freq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6601</th>\n",
       "      <td>lord</td>\n",
       "      <td>7222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4496</th>\n",
       "      <td>god</td>\n",
       "      <td>4096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6782</th>\n",
       "      <td>man</td>\n",
       "      <td>2500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6213</th>\n",
       "      <td>king</td>\n",
       "      <td>2304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5861</th>\n",
       "      <td>israel</td>\n",
       "      <td>2263</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        word  freq\n",
       "6601    lord  7222\n",
       "4496     god  4096\n",
       "6782     man  2500\n",
       "6213    king  2304\n",
       "5861  israel  2263"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_freq = counts_df.sum().reset_index()\n",
    "word_freq.columns = ['word', 'freq']\n",
    "\n",
    "word_freq = word_freq.sort(columns='freq', ascending=False)\n",
    "word_freq.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>freq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6601</th>\n",
       "      <td>lord</td>\n",
       "      <td>7222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4496</th>\n",
       "      <td>god</td>\n",
       "      <td>4096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6782</th>\n",
       "      <td>man</td>\n",
       "      <td>2500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6213</th>\n",
       "      <td>king</td>\n",
       "      <td>2304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5861</th>\n",
       "      <td>israel</td>\n",
       "      <td>2263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10006</th>\n",
       "      <td>son</td>\n",
       "      <td>2209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4826</th>\n",
       "      <td>hath</td>\n",
       "      <td>1957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2133</th>\n",
       "      <td>came</td>\n",
       "      <td>1955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8203</th>\n",
       "      <td>people</td>\n",
       "      <td>1862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2443</th>\n",
       "      <td>come</td>\n",
       "      <td>1792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5444</th>\n",
       "      <td>house</td>\n",
       "      <td>1787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7895</th>\n",
       "      <td>one</td>\n",
       "      <td>1751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>377</th>\n",
       "      <td>also</td>\n",
       "      <td>1618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2861</th>\n",
       "      <td>day</td>\n",
       "      <td>1616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2338</th>\n",
       "      <td>children</td>\n",
       "      <td>1576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6934</th>\n",
       "      <td>men</td>\n",
       "      <td>1537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6335</th>\n",
       "      <td>land</td>\n",
       "      <td>1533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9289</th>\n",
       "      <td>saying</td>\n",
       "      <td>1434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6448</th>\n",
       "      <td>let</td>\n",
       "      <td>1425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9602</th>\n",
       "      <td>shalt</td>\n",
       "      <td>1396</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           word  freq\n",
       "6601       lord  7222\n",
       "4496        god  4096\n",
       "6782        man  2500\n",
       "6213       king  2304\n",
       "5861     israel  2263\n",
       "10006       son  2209\n",
       "4826       hath  1957\n",
       "2133       came  1955\n",
       "8203     people  1862\n",
       "2443       come  1792\n",
       "5444      house  1787\n",
       "7895        one  1751\n",
       "377        also  1618\n",
       "2861        day  1616\n",
       "2338   children  1576\n",
       "6934        men  1537\n",
       "6335       land  1533\n",
       "9289     saying  1434\n",
       "6448        let  1425\n",
       "9602      shalt  1396"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_freq[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'aaron',\n",
       " u'aaronand',\n",
       " u'aaronites',\n",
       " u'aaronnumbered',\n",
       " u'aaronthe',\n",
       " u'abarim',\n",
       " u'abase',\n",
       " u'abased',\n",
       " u'abated',\n",
       " u'abba',\n",
       " u'abda',\n",
       " u'abdi',\n",
       " u'abdon',\n",
       " u'abednego',\n",
       " u'abel',\n",
       " u'abelbethmaachah',\n",
       " u'abelmeholah',\n",
       " u'abenjamite',\n",
       " u'abhor',\n",
       " u'abhorred',\n",
       " u'abhorrest',\n",
       " u'abhorreth',\n",
       " u'abia',\n",
       " u'abiah',\n",
       " u'abiathar',\n",
       " u'abiatharthe',\n",
       " u'abib',\n",
       " u'abidan',\n",
       " u'abide',\n",
       " u'abideth',\n",
       " u'abiding',\n",
       " u'abiel',\n",
       " u'abiezer',\n",
       " u'abigail',\n",
       " u'abihail',\n",
       " u'abihu',\n",
       " u'abijah',\n",
       " u'abijam',\n",
       " u'ability',\n",
       " u'abimelech',\n",
       " u'abinadab',\n",
       " u'abinoam',\n",
       " u'abiram',\n",
       " u'abishag',\n",
       " u'abishai',\n",
       " u'abishaihis',\n",
       " u'abishalom',\n",
       " u'abishua',\n",
       " u'abishur',\n",
       " u'abital',\n",
       " u'able',\n",
       " u'ablessing',\n",
       " u'ableto',\n",
       " u'abner',\n",
       " u'abode',\n",
       " u'abolished',\n",
       " u'abominable',\n",
       " u'abomination',\n",
       " u'abominations',\n",
       " u'abominationswhich',\n",
       " u'abond',\n",
       " u'abound',\n",
       " u'abounded',\n",
       " u'aboundeth',\n",
       " u'abounding',\n",
       " u'aboutfour',\n",
       " u'aboutthe',\n",
       " u'aboutthem',\n",
       " u'aboutto',\n",
       " u'aboutwith',\n",
       " u'aboveall',\n",
       " u'abovethe',\n",
       " u'abraham',\n",
       " u'abram',\n",
       " u'abrawling',\n",
       " u'abroad',\n",
       " u'absalom',\n",
       " u'absence',\n",
       " u'absent',\n",
       " u'abstain',\n",
       " u'abstainfrom',\n",
       " u'abullock',\n",
       " u'abundance',\n",
       " u'abundant',\n",
       " u'abundantly',\n",
       " u'aburnt',\n",
       " u'aburyingplace',\n",
       " u'abuse',\n",
       " u'accept',\n",
       " u'acceptable',\n",
       " u'acceptation',\n",
       " u'accepted',\n",
       " u'accepteth',\n",
       " u'access',\n",
       " u'accompanied',\n",
       " u'accomplish',\n",
       " u'accomplished',\n",
       " u'accord',\n",
       " u'according',\n",
       " u'accordingto',\n",
       " u'accordingunto',\n",
       " u'account',\n",
       " u'accounted',\n",
       " u'accursed',\n",
       " u'accursedthing',\n",
       " u'accusation',\n",
       " u'accuse',\n",
       " u'accused',\n",
       " u'accusedhim',\n",
       " u'accusers',\n",
       " u'acenturion',\n",
       " u'acertain',\n",
       " u'achaia',\n",
       " u'achan',\n",
       " u'achbor',\n",
       " u'achild',\n",
       " u'achish',\n",
       " u'achor',\n",
       " u'achsah',\n",
       " u'achshaph',\n",
       " u'achzib',\n",
       " u'acity',\n",
       " u'acknowledge',\n",
       " u'acknowledged',\n",
       " u'acknowledging',\n",
       " u'acloth',\n",
       " u'acloud',\n",
       " u'acommandment',\n",
       " u'acovenant',\n",
       " u'acovering',\n",
       " u'acquaintance',\n",
       " u'acrown',\n",
       " u'act',\n",
       " u'acts',\n",
       " u'acubit',\n",
       " u'acurse',\n",
       " u'adah',\n",
       " u'adaiah',\n",
       " u'adam',\n",
       " u'adamant',\n",
       " u'adar',\n",
       " u'adbeel',\n",
       " u'add',\n",
       " u'added',\n",
       " u'adder',\n",
       " u'addeth',\n",
       " u'additions',\n",
       " u'adecree',\n",
       " u'aderision',\n",
       " u'adesolation',\n",
       " u'adestroying',\n",
       " u'adevil',\n",
       " u'adiel',\n",
       " u'adin',\n",
       " u'adjure',\n",
       " u'admah',\n",
       " u'admonish',\n",
       " u'admonished',\n",
       " u'admonition',\n",
       " u'adna',\n",
       " u'adnah',\n",
       " u'adog',\n",
       " u'adonibezek',\n",
       " u'adonijah',\n",
       " u'adonikam',\n",
       " u'adonizedec',\n",
       " u'adoption',\n",
       " u'adorn',\n",
       " u'adorned',\n",
       " u'adrammelech',\n",
       " u'adriel',\n",
       " u'adry',\n",
       " u'adullam',\n",
       " u'adullamite',\n",
       " u'adulterers',\n",
       " u'adulteress',\n",
       " u'adulteresses',\n",
       " u'adulteries',\n",
       " u'adulterous',\n",
       " u'adultery',\n",
       " u'advanced',\n",
       " u'advantage',\n",
       " u'adversaries',\n",
       " u'adversary',\n",
       " u'adversities',\n",
       " u'adversity',\n",
       " u'advertise',\n",
       " u'advice',\n",
       " u'advise',\n",
       " u'advised',\n",
       " u'aeneas',\n",
       " u'afair',\n",
       " u'afar',\n",
       " u'afaroff',\n",
       " u'afather',\n",
       " u'afeast',\n",
       " u'affairs',\n",
       " u'affected',\n",
       " u'affection',\n",
       " u'affirm',\n",
       " u'afflict',\n",
       " u'afflicted',\n",
       " u'afflictedus',\n",
       " u'affliction',\n",
       " u'afflictionand',\n",
       " u'afflictions',\n",
       " u'afflictyour',\n",
       " u'affrighted',\n",
       " u'aflying',\n",
       " u'afool',\n",
       " u'afore',\n",
       " u'aforetime',\n",
       " u'afountain',\n",
       " u'afraid',\n",
       " u'afraidof',\n",
       " u'afterabner',\n",
       " u'afterhim',\n",
       " u'afterhis',\n",
       " u'afterthat',\n",
       " u'afterthe',\n",
       " u'afterthee',\n",
       " u'aftertheir',\n",
       " u'afterthem',\n",
       " u'afterthis',\n",
       " u'afterward',\n",
       " u'afterwards',\n",
       " u'afteryou',\n",
       " u'agabus',\n",
       " u'agag',\n",
       " u'agagite',\n",
       " u'againfrom',\n",
       " u'againinto',\n",
       " u'againstall',\n",
       " u'againsthim',\n",
       " u'againstisrael',\n",
       " u'againstjehoshaphat',\n",
       " u'againstjerusalem',\n",
       " u'againstkingdom',\n",
       " u'againstme',\n",
       " u'againstnation',\n",
       " u'againstsennacherib',\n",
       " u'againstthe',\n",
       " u'againstthee',\n",
       " u'againstthem',\n",
       " u'againstthis',\n",
       " u'againstyou',\n",
       " u'againstyour',\n",
       " u'againthe',\n",
       " u'againto',\n",
       " u'againunto',\n",
       " u'agalilaean',\n",
       " u'agarment',\n",
       " u'agate',\n",
       " u'age',\n",
       " u'aged',\n",
       " u'ages',\n",
       " u'agirdle',\n",
       " u'ago',\n",
       " u'agod',\n",
       " u'agood',\n",
       " u'agoodly',\n",
       " u'agreat',\n",
       " u'agreater',\n",
       " u'agree',\n",
       " u'agreed',\n",
       " u'agreement',\n",
       " u'agreeth',\n",
       " u'agrippa',\n",
       " u'ah',\n",
       " u'aha',\n",
       " u'ahab',\n",
       " u'ahalf',\n",
       " u'ahasuerus',\n",
       " u'ahava',\n",
       " u'ahaz',\n",
       " u'ahaziah',\n",
       " u'ahi',\n",
       " u'ahiah',\n",
       " u'ahiam',\n",
       " u'ahiezer',\n",
       " u'ahijah',\n",
       " u'ahikam',\n",
       " u'ahilud',\n",
       " u'ahimaaz',\n",
       " u'ahimelech',\n",
       " u'ahinoam',\n",
       " u'ahio',\n",
       " u'ahira',\n",
       " u'ahisamach',\n",
       " u'ahithophel',\n",
       " u'ahitub',\n",
       " u'ahlai',\n",
       " u'ahlord',\n",
       " u'ahohite',\n",
       " u'aholah',\n",
       " u'aholiab',\n",
       " u'aholibah',\n",
       " u'aholibamah',\n",
       " u'ai',\n",
       " u'aiah',\n",
       " u'aijalon',\n",
       " u'aileth',\n",
       " u'ain',\n",
       " u'air',\n",
       " u'ajalon',\n",
       " u'ajavelin',\n",
       " u'ajew',\n",
       " u'ajudge',\n",
       " u'akingdom',\n",
       " u'akkub',\n",
       " u'akrabbim',\n",
       " u'alabaster',\n",
       " u'alamb',\n",
       " u'alamp',\n",
       " u'aland',\n",
       " u'alarm',\n",
       " u'alas',\n",
       " u'albeit',\n",
       " u'alemeth',\n",
       " u'alexander',\n",
       " u'alexandria',\n",
       " u'algum',\n",
       " u'aliar',\n",
       " u'alie',\n",
       " u'alien',\n",
       " u'alienated',\n",
       " u'aliens',\n",
       " u'alight',\n",
       " u'alike',\n",
       " u'aline',\n",
       " u'alittle',\n",
       " u'alive',\n",
       " u'allagainst',\n",
       " u'alleluia',\n",
       " u'allflesh',\n",
       " u'allgenerations',\n",
       " u'allhave',\n",
       " u'allhis',\n",
       " u'allisrael',\n",
       " u'alljudaea',\n",
       " u'alljudah',\n",
       " u'allmanner',\n",
       " u'allmen',\n",
       " u'allmy',\n",
       " u'allnations',\n",
       " u'allnight',\n",
       " u'allof',\n",
       " u'allon',\n",
       " u'allow',\n",
       " u'allpeople',\n",
       " u'allthat',\n",
       " u'allthe',\n",
       " u'alltheir',\n",
       " u'allthem',\n",
       " u'allthese',\n",
       " u'allthine',\n",
       " u'allthings',\n",
       " u'allthis',\n",
       " u'allthy',\n",
       " u'allye',\n",
       " u'allyour',\n",
       " u'almighty',\n",
       " u'almightypervert',\n",
       " u'almodad',\n",
       " u'almond',\n",
       " u'almondiblathaim',\n",
       " u'almonds',\n",
       " u'almost',\n",
       " u'alms',\n",
       " u'almug',\n",
       " u'aloes',\n",
       " u'alone',\n",
       " u'along',\n",
       " u'aloud',\n",
       " u'alpha',\n",
       " u'alphaeus',\n",
       " u'already',\n",
       " u'also',\n",
       " u'alsofor',\n",
       " u'alsoin',\n",
       " u'alsoof',\n",
       " u'alsoshall',\n",
       " u'alsoshalt',\n",
       " u'alsothe',\n",
       " u'alsothey',\n",
       " u'alsoto',\n",
       " u'alsounto',\n",
       " u'alsowas',\n",
       " u'alsowe',\n",
       " u'altar',\n",
       " u'altarin',\n",
       " u'altarround',\n",
       " u'altars',\n",
       " u'alter',\n",
       " u'altered',\n",
       " u'although',\n",
       " u'altogether',\n",
       " u'alush',\n",
       " u'alway',\n",
       " u'always',\n",
       " u'amagainst',\n",
       " u'amalek',\n",
       " u'amalekite',\n",
       " u'amalekites',\n",
       " u'aman',\n",
       " u'amariah',\n",
       " u'amasa',\n",
       " u'amasai',\n",
       " u'amashamed',\n",
       " u'amazed',\n",
       " u'amaziah',\n",
       " u'ambassador',\n",
       " u'ambassadors',\n",
       " u'amber',\n",
       " u'ambush',\n",
       " u'amcome',\n",
       " u'amemorial',\n",
       " u'amen',\n",
       " u'amend',\n",
       " u'amerry',\n",
       " u'amethyst',\n",
       " u'ami',\n",
       " u'amighty',\n",
       " u'aminadab',\n",
       " u'amiss',\n",
       " u'amittai',\n",
       " u'ammiel',\n",
       " u'ammihud',\n",
       " u'amminadab',\n",
       " u'ammishaddai',\n",
       " u'ammon',\n",
       " u'ammonite',\n",
       " u'ammonites',\n",
       " u'ammonitess',\n",
       " u'amnon',\n",
       " u'amnot',\n",
       " u'amok',\n",
       " u'amon',\n",
       " u'among',\n",
       " u'amongall',\n",
       " u'amongst',\n",
       " u'amongthe',\n",
       " u'amongthem',\n",
       " u'amongthemselves',\n",
       " u'amongthy',\n",
       " u'amongyou',\n",
       " u'amorite',\n",
       " u'amorites',\n",
       " u'amos',\n",
       " u'amount',\n",
       " u'amountain',\n",
       " u'amoz',\n",
       " u'amram',\n",
       " u'amramites',\n",
       " u'amraphel',\n",
       " u'amthe',\n",
       " u'amultitude',\n",
       " u'amurderer',\n",
       " u'amzi',\n",
       " u'anab',\n",
       " u'anabomination',\n",
       " u'anah',\n",
       " u'anak',\n",
       " u'anakims',\n",
       " u'analtar',\n",
       " u'anamim',\n",
       " u'anangel',\n",
       " u'ananiah',\n",
       " u'ananias',\n",
       " u'anastonishment',\n",
       " u'anath',\n",
       " u'anathoth',\n",
       " u'anation',\n",
       " u'anatonement',\n",
       " u'anchors',\n",
       " u'ancient',\n",
       " u'ancients',\n",
       " u'ancienttimes',\n",
       " u'anda',\n",
       " u'andaaron',\n",
       " u'andabiathar',\n",
       " u'andabimael',\n",
       " u'andabove',\n",
       " u'andabraham',\n",
       " u'andabsalom',\n",
       " u'andacceptable',\n",
       " u'andaccording',\n",
       " u'andafter',\n",
       " u'andafterward',\n",
       " u'andagain',\n",
       " u'andagainst',\n",
       " u'andahaz',\n",
       " u'andahiman',\n",
       " u'andahimelech',\n",
       " u'andall',\n",
       " u'andalso',\n",
       " u'andamong',\n",
       " u'andan',\n",
       " u'andanointed',\n",
       " u'andanother',\n",
       " u'andanswer',\n",
       " u'andanswered',\n",
       " u'andantioch',\n",
       " u'andas',\n",
       " u'andasahiah',\n",
       " u'andashes',\n",
       " u'andasses',\n",
       " u'andat',\n",
       " u'andathaliah',\n",
       " u'andazariah',\n",
       " u'andbaalath',\n",
       " u'andbarnabas',\n",
       " u'andbe',\n",
       " u'andbeast',\n",
       " u'andbecame',\n",
       " u'andbecause',\n",
       " u'andbefore',\n",
       " u'andbegan',\n",
       " u'andbegat',\n",
       " u'andbeginning',\n",
       " u'andbehind',\n",
       " u'andbehold',\n",
       " u'andbenjamin',\n",
       " u'andberiah',\n",
       " u'andbeside',\n",
       " u'andbesought',\n",
       " u'andbethel',\n",
       " u'andbethshemesh',\n",
       " u'andblessed',\n",
       " u'andbound',\n",
       " u'andbowed',\n",
       " u'andbrake',\n",
       " u'andbread',\n",
       " u'andbringeth',\n",
       " u'andbringing',\n",
       " u'andbrought',\n",
       " u'andburied',\n",
       " u'andburn',\n",
       " u'andburned',\n",
       " u'andbuy',\n",
       " u'andby',\n",
       " u'andcalled',\n",
       " u'andcame',\n",
       " u'andcaptains',\n",
       " u'andcarmi',\n",
       " u'andcarried',\n",
       " u'andcast',\n",
       " u'andcaused',\n",
       " u'andchariots',\n",
       " u'andcities',\n",
       " u'andcome',\n",
       " u'andcommanded',\n",
       " u'andcommandments',\n",
       " u'andcommit',\n",
       " u'andcommitted',\n",
       " u'andcommitteth',\n",
       " u'andconcerning',\n",
       " u'andconfess',\n",
       " u'andcould',\n",
       " u'andcovered',\n",
       " u'andcried',\n",
       " u'andcustom',\n",
       " u'andcut',\n",
       " u'anddaughters',\n",
       " u'anddavid',\n",
       " u'anddead',\n",
       " u'anddeclare',\n",
       " u'anddefiled',\n",
       " u'anddeliver',\n",
       " u'anddelivered',\n",
       " u'anddeparted',\n",
       " u'anddespise',\n",
       " u'anddestroy',\n",
       " u'anddestroyed',\n",
       " u'anddid',\n",
       " u'anddivide',\n",
       " u'anddo',\n",
       " u'anddoctrines',\n",
       " u'anddown',\n",
       " u'anddrew',\n",
       " u'anddrink',\n",
       " u'anddrinketh',\n",
       " u'anddwelt',\n",
       " u'andeat',\n",
       " u'andeight',\n",
       " u'andelders',\n",
       " u'andeleazar',\n",
       " u'andenquired',\n",
       " u'andenvy',\n",
       " u'andephraim',\n",
       " u'andequity',\n",
       " u'andever',\n",
       " u'andevery',\n",
       " u'andfeed',\n",
       " u'andfell',\n",
       " u'andfemale',\n",
       " u'andfenced',\n",
       " u'andfilled',\n",
       " u'andfine',\n",
       " u'andfire',\n",
       " u'andfive',\n",
       " u'andfled',\n",
       " u'andfollowed',\n",
       " u'andfor',\n",
       " u'andfought',\n",
       " u'andfound',\n",
       " u'andfour',\n",
       " u'andfrom',\n",
       " u'andgather',\n",
       " u'andgave',\n",
       " u'andgive',\n",
       " u'andgiven',\n",
       " u'andgiveth',\n",
       " u'andgo',\n",
       " u'andgold',\n",
       " u'andgomorrha',\n",
       " u'andgreat',\n",
       " u'andhad',\n",
       " u'andhast',\n",
       " u'andhasted',\n",
       " u'andhath',\n",
       " u'andhave',\n",
       " u'andhaving',\n",
       " u'andhe',\n",
       " u'andhear',\n",
       " u'andheat',\n",
       " u'andheaven',\n",
       " u'andhedges',\n",
       " u'andher',\n",
       " u'andherds',\n",
       " u'andhezekiah',\n",
       " u'andhid',\n",
       " u'andhide',\n",
       " u'andhis',\n",
       " u'andhoney',\n",
       " u'andhonour',\n",
       " u'andhorse',\n",
       " u'andhorsemen',\n",
       " u'andhow',\n",
       " u'andhuram',\n",
       " u'andi',\n",
       " u'andif',\n",
       " u'andimmediately',\n",
       " u'andin',\n",
       " u'andinto',\n",
       " u'andisrael',\n",
       " u'andit',\n",
       " u'andivah',\n",
       " u'andjacob',\n",
       " u'andjerah',\n",
       " u'andjeremiah',\n",
       " u'andjerusalem',\n",
       " u'andjesus',\n",
       " u'andjohn',\n",
       " u'andjonathan',\n",
       " u'andjoseph',\n",
       " u'andjoshua',\n",
       " u'andjudah',\n",
       " u'andjudgeth',\n",
       " u'andjudgment',\n",
       " u'andjudgments',\n",
       " u'andjustice',\n",
       " u'andkeep',\n",
       " u'andkeepeth',\n",
       " u'andkilled',\n",
       " u'andkissed',\n",
       " u'andknow',\n",
       " u'andknowledge',\n",
       " u'andlabour',\n",
       " u'andlaid',\n",
       " u'andlay',\n",
       " u'andleave',\n",
       " u'andlet',\n",
       " u'andlift',\n",
       " u'andlifted',\n",
       " u'andlived',\n",
       " u'andlooked',\n",
       " u'andlove',\n",
       " u'andmade',\n",
       " u'andmake',\n",
       " u'andmakest',\n",
       " u'andmaketh',\n",
       " u'andmany',\n",
       " u'andmarry',\n",
       " u'andmeat',\n",
       " u'andmerciful',\n",
       " u'andmercy',\n",
       " u'andminister',\n",
       " u'andministered',\n",
       " u'andmore',\n",
       " u'andmoses',\n",
       " u'andmultiply',\n",
       " u'andmurderers',\n",
       " u'andmy',\n",
       " u'andnathan',\n",
       " u'andnight',\n",
       " u'andnone',\n",
       " u'andnot',\n",
       " u'andnow',\n",
       " u'andof',\n",
       " u'andoffered',\n",
       " u'andold',\n",
       " u'andon',\n",
       " u'andone',\n",
       " u'andothers',\n",
       " u'andout',\n",
       " u'andover',\n",
       " u'andpass',\n",
       " u'andpassed',\n",
       " u'andpeace',\n",
       " u'andpeople',\n",
       " u'andperish',\n",
       " u'andpersians',\n",
       " u'andpharaoh',\n",
       " u'andpitched',\n",
       " u'andplant',\n",
       " u'andpossess',\n",
       " u'andpoured',\n",
       " u'andpraise',\n",
       " u'andprayed',\n",
       " u'andpreached',\n",
       " u'andprecious',\n",
       " u'andprepare',\n",
       " u'andprevailed',\n",
       " u'andprinces',\n",
       " u'andproclaimed',\n",
       " u'andpurple',\n",
       " u'andpursued',\n",
       " u'andput',\n",
       " u'andraiment',\n",
       " u'andreceived',\n",
       " u'andreigned',\n",
       " u'andrejoice',\n",
       " u'andreturned',\n",
       " u'andrew',\n",
       " u'andright',\n",
       " u'andrighteousness',\n",
       " u'andsacrifices',\n",
       " u'andsaid',\n",
       " u'andsaith',\n",
       " u'andsamaria',\n",
       " u'andsamuel',\n",
       " u'andsanctified',\n",
       " u'andsanctify',\n",
       " u'andsaul',\n",
       " u'andsay',\n",
       " u'andsaying',\n",
       " u'andscarlet',\n",
       " u'andscorpions',\n",
       " u'andsee',\n",
       " u'andseeth',\n",
       " u'andsend',\n",
       " u'andsent',\n",
       " u'andserve',\n",
       " u'andserved',\n",
       " u'andset',\n",
       " u'andseven',\n",
       " u'andshall',\n",
       " u'andshalt',\n",
       " u'andshe',\n",
       " u'andsheep',\n",
       " u'andshemiramoth',\n",
       " u'andshut',\n",
       " u'andsidon',\n",
       " u'andsilver',\n",
       " u'andsinging',\n",
       " u'andsit',\n",
       " u'andsix',\n",
       " u'andsixteen',\n",
       " u'andslay',\n",
       " u'andslew',\n",
       " u'andsmite',\n",
       " u'andsmote',\n",
       " u'andso',\n",
       " u'andsome',\n",
       " u'andspake',\n",
       " u'andspeak',\n",
       " u'andspirit',\n",
       " u'andsprinkle',\n",
       " u'andstamped',\n",
       " u'andstand',\n",
       " u'andstayed',\n",
       " u'andstone',\n",
       " u'andstood',\n",
       " u'andstraightway',\n",
       " u'andstrangers',\n",
       " u'andstrength',\n",
       " u'andsupplication',\n",
       " u'andsupplications',\n",
       " u'andsweet',\n",
       " u'andtake',\n",
       " u'andtaught',\n",
       " u'andtell',\n",
       " u'andten',\n",
       " u'andthat',\n",
       " u'andthe',\n",
       " u'andtheir',\n",
       " u'andthem',\n",
       " u'andthere',\n",
       " u'andtherefore',\n",
       " u'andthey',\n",
       " u'andthick',\n",
       " u'andthine',\n",
       " u'andthirtieth',\n",
       " u'andthirty',\n",
       " u'andthis',\n",
       " u'andthose',\n",
       " u'andthou',\n",
       " u'andthough',\n",
       " u'andthree',\n",
       " u'andthreescore',\n",
       " u'andthrough',\n",
       " u'andthus',\n",
       " u'andthy',\n",
       " u'andto',\n",
       " u'andtold',\n",
       " u'andtook',\n",
       " u'andtoward',\n",
       " u'andtruth',\n",
       " u'andtubal',\n",
       " u'andturned',\n",
       " u'andturneth',\n",
       " u'andtwelve',\n",
       " u'andtwentieth',\n",
       " u'andtwenty',\n",
       " u'andtwo',\n",
       " u'andunder',\n",
       " u'andunderstanding',\n",
       " u'andunleavened',\n",
       " u'andunto',\n",
       " u'andupon',\n",
       " u'andupward',\n",
       " u'andvery',\n",
       " u'andvessels',\n",
       " u'andvexation',\n",
       " u'andvoices',\n",
       " u'andwalk',\n",
       " u'andwalked',\n",
       " u'andwas',\n",
       " u'andwash',\n",
       " u'andwasted',\n",
       " u'andwe',\n",
       " u'andweeping',\n",
       " u'andwent',\n",
       " u'andwept',\n",
       " u'andwere',\n",
       " u'andwhat',\n",
       " u'andwhatsoever',\n",
       " u'andwhen',\n",
       " u'andwho',\n",
       " u'andwhosoever',\n",
       " u'andwill',\n",
       " u'andwine',\n",
       " u'andwisdom',\n",
       " u'andwith',\n",
       " u'andwithout',\n",
       " u'andwomen',\n",
       " u'andwonders',\n",
       " u'andworshipped',\n",
       " u'andwould',\n",
       " u'andye',\n",
       " u'andyour',\n",
       " u'andzalmunna',\n",
       " u'andzebadiah',\n",
       " u'andzebulun',\n",
       " u'andzechariah',\n",
       " u'andzephaniah',\n",
       " u'andziklag',\n",
       " u'anephah',\n",
       " u'aner',\n",
       " u'aneverlasting',\n",
       " u'anevil',\n",
       " u'angel',\n",
       " u'angelof',\n",
       " u'angels',\n",
       " u'anger',\n",
       " u'angeragainst',\n",
       " u'angle',\n",
       " u'angry',\n",
       " u'anguish',\n",
       " u'anhandmaid',\n",
       " u'anharlot',\n",
       " u'anheave',\n",
       " u'anhebrew',\n",
       " u'anheifer',\n",
       " u'anhissing',\n",
       " u'anholy',\n",
       " u'anhouse',\n",
       " u'anhouseholder',\n",
       " u'anhundred',\n",
       " u'anhundredfold',\n",
       " u'aninhabitant',\n",
       " u'aninheritance',\n",
       " u'aninstrument',\n",
       " u'annas',\n",
       " u'anoath',\n",
       " u'anoffering',\n",
       " u'anoint',\n",
       " u'anointed',\n",
       " u'anointedhim',\n",
       " u'anointing',\n",
       " u'anon',\n",
       " u'another',\n",
       " u'anotherplace',\n",
       " u'anothertribe',\n",
       " u'answer',\n",
       " u'answered',\n",
       " u'answeredand',\n",
       " u'answeredst',\n",
       " u'answerest',\n",
       " u'answereth',\n",
       " u'answering',\n",
       " u'answerthem',\n",
       " u'antioch',\n",
       " u'antothite',\n",
       " u'anunclean',\n",
       " u'anunderstanding',\n",
       " u'anymore',\n",
       " u'anyof',\n",
       " u'anyperson',\n",
       " u'anysuch',\n",
       " u'anything',\n",
       " u'apace',\n",
       " u'apart',\n",
       " u'apeople',\n",
       " u'aperpetual',\n",
       " u'apes',\n",
       " u'apharsachites',\n",
       " u'aphek',\n",
       " u'aphysician',\n",
       " u'apiece',\n",
       " u'apillar',\n",
       " u'aplace',\n",
       " u'apledge',\n",
       " u'apollos',\n",
       " u'apomegranate',\n",
       " u'apossession',\n",
       " u'apostle',\n",
       " u'apostles',\n",
       " u'apostleship',\n",
       " u'apothecary',\n",
       " u'appaim',\n",
       " u'apparel',\n",
       " u'apparelled',\n",
       " u'appealed',\n",
       " u'appealunto',\n",
       " u'appear',\n",
       " u'appearance',\n",
       " u'appearances',\n",
       " u'appeared',\n",
       " u'appearedto',\n",
       " u'appeareth',\n",
       " u'appearing',\n",
       " u'appeased',\n",
       " u'appertained',\n",
       " u'appertaineth',\n",
       " u'appetite',\n",
       " u'apple',\n",
       " u'apples',\n",
       " u'applied',\n",
       " u'apply',\n",
       " u'applythine',\n",
       " u'appoint',\n",
       " u'appointed',\n",
       " u'appointment',\n",
       " u'apprehend',\n",
       " u'apprehended',\n",
       " u'approach',\n",
       " u'approached',\n",
       " u'approve',\n",
       " u'approved',\n",
       " u'apresent',\n",
       " u'aprey',\n",
       " u'apriest',\n",
       " u'aprince',\n",
       " u'aprophet',\n",
       " u'aproverb',\n",
       " u'apt',\n",
       " u'aquarrel',\n",
       " u'aquila',\n",
       " u'ar',\n",
       " u'arabia',\n",
       " u'arabian',\n",
       " u'arabians',\n",
       " u'arad',\n",
       " u'arah',\n",
       " u'aram',\n",
       " u'aran',\n",
       " u'ararat',\n",
       " u'araunah',\n",
       " u'arba',\n",
       " u'arbathite',\n",
       " u'archangel',\n",
       " u'archer',\n",
       " u'archers',\n",
       " u'arches',\n",
       " u'archesthereof',\n",
       " u'archippus',\n",
       " u'archite',\n",
       " u'arcturus',\n",
       " ...]"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# ######allathabibles (scrapedstuff)######  this gave an error\n",
    "# vectorizer = CountVectorizer(stop_words=archaic_stopwords, \n",
    "#                              token_pattern='[A-Za-z]+', min_df=2)\n",
    "\n",
    "# count_vectorized_bibles = {}\n",
    "# for name in tqdm(versions.keys()):\n",
    "#     single_bible_corpus = bibles_df.loc[:, name]\n",
    "#     vectorized = vectorizer.fit_transform(single_bible_corpus)\n",
    "#     vector_array = vectorized.toarray()\n",
    "#     counts_df = pd.DataFrame(vecs_bible_array, columns=vectorizer.get_feature_names())\n",
    "#     count_vectorized_bibles[name] = counts_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#2a. tf-idf (see if this will make for better inertia)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class sklearn.feature_extraction.text.TfidfVectorizer\n",
    "\n",
    "do this for rows instead of columns?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#3. LDA topic modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import lda"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####allthebibles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2, 3, 4, 5]"
      ]
     },
     "execution_count": 381,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "range(1,6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def lda_topic_model(matrix, numtopics=range(1,6)):\n",
    "    topic_models = {}\n",
    "    for n in numtopics:\n",
    "        model = lda.LDA(n_topics=n, n_iter=100, random_state=1) #n_iter could be higher?\n",
    "        model.fit_transform(matrix)\n",
    "        topic_models[n] = model\n",
    "    return topic_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 472,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "lda_genesis_models = {}\n",
    "for name in tqdm(version_names):\n",
    "    lda_model = lda_topic_model(cv_genesis[name][1])\n",
    "    lda_genesis_models[name] = lda_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 473,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('lda_genesis_models.pkl', 'w') as picklefile:\n",
    "    pickle.dump(lda_genesis_models, picklefile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 478,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "genesis_topwords = {}\n",
    "for name, models in lda_genesis_models.items():\n",
    "    topwords = view_topics(models, cv_genesis[name][0])\n",
    "    genesis_topwords[name] = topwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 503,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "genesis_topics = {}\n",
    "for name, numtopics in genesis_topwords.items():\n",
    "    topics = [t[9:] for t in numtopics[3]]\n",
    "    genesis_topics[name] = ' '.join(topics)\n",
    "    #print name \n",
    "    #print numtopics[3] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#now, we're going to try to see how different these works really are"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 506,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import jaccard_similarity_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 552,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "JankyAssMatrix = []\n",
    "for name, text1 in genesis_topics.items():\n",
    "    matrix_row = []\n",
    "    text1 = text1.split()\n",
    "    for name, text2 in genesis_topics.items():\n",
    "        text2 = text2.split()\n",
    "        j_score = jaccard_similarity_score(text1, text2)\n",
    "        matrix_row.append(j_score)\n",
    "    JankyAssMatrix.append(matrix_row)\n",
    "JankyAssMatrix = np.matrix(JankyAssMatrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 553,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[ 1.        ,  0.        ,  0.02777778,  0.02777778,  0.02777778,\n",
       "          0.11111111,  0.        ,  0.        ,  0.05555556,  0.02777778,\n",
       "          0.02777778,  0.        ,  0.        ,  0.02777778,  0.        ,\n",
       "          0.11111111,  0.05555556,  0.11111111,  0.05555556,  0.02777778,\n",
       "          0.05555556,  0.02777778,  0.02777778,  0.05555556],\n",
       "        [ 0.        ,  1.        ,  0.        ,  0.05555556,  0.02777778,\n",
       "          0.05555556,  0.02777778,  0.        ,  0.02777778,  0.02777778,\n",
       "          0.05555556,  0.02777778,  0.02777778,  0.11111111,  0.05555556,\n",
       "          0.        ,  0.05555556,  0.        ,  0.02777778,  0.        ,\n",
       "          0.        ,  0.        ,  0.05555556,  0.11111111],\n",
       "        [ 0.02777778,  0.        ,  1.        ,  0.02777778,  0.        ,\n",
       "          0.        ,  0.        ,  0.05555556,  0.        ,  0.02777778,\n",
       "          0.02777778,  0.02777778,  0.02777778,  0.        ,  0.02777778,\n",
       "          0.02777778,  0.02777778,  0.        ,  0.02777778,  0.02777778,\n",
       "          0.02777778,  0.11111111,  0.08333333,  0.        ],\n",
       "        [ 0.02777778,  0.05555556,  0.02777778,  1.        ,  0.        ,\n",
       "          0.02777778,  0.        ,  0.08333333,  0.        ,  0.        ,\n",
       "          0.        ,  0.11111111,  0.13888889,  0.08333333,  0.        ,\n",
       "          0.02777778,  0.02777778,  0.        ,  0.02777778,  0.02777778,\n",
       "          0.        ,  0.        ,  0.02777778,  0.05555556],\n",
       "        [ 0.02777778,  0.02777778,  0.        ,  0.        ,  1.        ,\n",
       "          0.        ,  0.        ,  0.02777778,  0.05555556,  0.13888889,\n",
       "          0.05555556,  0.02777778,  0.02777778,  0.        ,  0.02777778,\n",
       "          0.        ,  0.        ,  0.02777778,  0.02777778,  0.02777778,\n",
       "          0.02777778,  0.        ,  0.        ,  0.02777778],\n",
       "        [ 0.11111111,  0.05555556,  0.        ,  0.02777778,  0.        ,\n",
       "          1.        ,  0.        ,  0.08333333,  0.02777778,  0.        ,\n",
       "          0.05555556,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "          0.11111111,  0.19444444,  0.13888889,  0.05555556,  0.05555556,\n",
       "          0.05555556,  0.05555556,  0.05555556,  0.19444444],\n",
       "        [ 0.        ,  0.02777778,  0.        ,  0.        ,  0.        ,\n",
       "          0.        ,  1.        ,  0.        ,  0.        ,  0.02777778,\n",
       "          0.02777778,  0.02777778,  0.02777778,  0.02777778,  0.02777778,\n",
       "          0.02777778,  0.        ,  0.        ,  0.05555556,  0.02777778,\n",
       "          0.02777778,  0.02777778,  0.        ,  0.        ],\n",
       "        [ 0.        ,  0.        ,  0.05555556,  0.08333333,  0.02777778,\n",
       "          0.08333333,  0.        ,  1.        ,  0.05555556,  0.02777778,\n",
       "          0.        ,  0.05555556,  0.        ,  0.02777778,  0.02777778,\n",
       "          0.05555556,  0.05555556,  0.05555556,  0.02777778,  0.        ,\n",
       "          0.02777778,  0.        ,  0.02777778,  0.05555556],\n",
       "        [ 0.05555556,  0.02777778,  0.        ,  0.        ,  0.05555556,\n",
       "          0.02777778,  0.        ,  0.05555556,  1.        ,  0.08333333,\n",
       "          0.02777778,  0.02777778,  0.02777778,  0.02777778,  0.05555556,\n",
       "          0.02777778,  0.02777778,  0.        ,  0.02777778,  0.05555556,\n",
       "          0.02777778,  0.02777778,  0.        ,  0.08333333],\n",
       "        [ 0.02777778,  0.02777778,  0.02777778,  0.        ,  0.13888889,\n",
       "          0.        ,  0.02777778,  0.02777778,  0.08333333,  1.        ,\n",
       "          0.02777778,  0.02777778,  0.05555556,  0.        ,  0.02777778,\n",
       "          0.        ,  0.        ,  0.05555556,  0.02777778,  0.05555556,\n",
       "          0.08333333,  0.        ,  0.08333333,  0.        ],\n",
       "        [ 0.02777778,  0.05555556,  0.02777778,  0.        ,  0.05555556,\n",
       "          0.05555556,  0.02777778,  0.        ,  0.02777778,  0.02777778,\n",
       "          1.        ,  0.02777778,  0.        ,  0.        ,  0.02777778,\n",
       "          0.02777778,  0.02777778,  0.05555556,  0.08333333,  0.        ,\n",
       "          0.        ,  0.02777778,  0.        ,  0.08333333],\n",
       "        [ 0.        ,  0.02777778,  0.02777778,  0.11111111,  0.02777778,\n",
       "          0.        ,  0.02777778,  0.05555556,  0.02777778,  0.02777778,\n",
       "          0.02777778,  1.        ,  0.19444444,  0.05555556,  0.        ,\n",
       "          0.02777778,  0.        ,  0.08333333,  0.        ,  0.02777778,\n",
       "          0.        ,  0.        ,  0.        ,  0.02777778],\n",
       "        [ 0.        ,  0.02777778,  0.02777778,  0.13888889,  0.02777778,\n",
       "          0.        ,  0.02777778,  0.        ,  0.02777778,  0.05555556,\n",
       "          0.        ,  0.19444444,  1.        ,  0.02777778,  0.        ,\n",
       "          0.        ,  0.        ,  0.05555556,  0.        ,  0.05555556,\n",
       "          0.        ,  0.02777778,  0.        ,  0.02777778],\n",
       "        [ 0.02777778,  0.11111111,  0.        ,  0.08333333,  0.        ,\n",
       "          0.        ,  0.02777778,  0.02777778,  0.02777778,  0.        ,\n",
       "          0.        ,  0.05555556,  0.02777778,  1.        ,  0.05555556,\n",
       "          0.08333333,  0.02777778,  0.02777778,  0.        ,  0.02777778,\n",
       "          0.        ,  0.02777778,  0.        ,  0.05555556],\n",
       "        [ 0.        ,  0.05555556,  0.02777778,  0.        ,  0.02777778,\n",
       "          0.        ,  0.02777778,  0.02777778,  0.05555556,  0.02777778,\n",
       "          0.02777778,  0.        ,  0.        ,  0.05555556,  1.        ,\n",
       "          0.08333333,  0.        ,  0.02777778,  0.08333333,  0.02777778,\n",
       "          0.02777778,  0.02777778,  0.02777778,  0.08333333],\n",
       "        [ 0.11111111,  0.        ,  0.02777778,  0.02777778,  0.        ,\n",
       "          0.11111111,  0.02777778,  0.05555556,  0.02777778,  0.        ,\n",
       "          0.02777778,  0.02777778,  0.        ,  0.08333333,  0.08333333,\n",
       "          1.        ,  0.08333333,  0.11111111,  0.08333333,  0.05555556,\n",
       "          0.08333333,  0.05555556,  0.        ,  0.19444444],\n",
       "        [ 0.05555556,  0.05555556,  0.02777778,  0.02777778,  0.        ,\n",
       "          0.19444444,  0.        ,  0.05555556,  0.02777778,  0.        ,\n",
       "          0.02777778,  0.        ,  0.        ,  0.02777778,  0.        ,\n",
       "          0.08333333,  1.        ,  0.11111111,  0.16666667,  0.        ,\n",
       "          0.05555556,  0.11111111,  0.08333333,  0.08333333],\n",
       "        [ 0.11111111,  0.        ,  0.        ,  0.        ,  0.02777778,\n",
       "          0.13888889,  0.        ,  0.05555556,  0.        ,  0.05555556,\n",
       "          0.05555556,  0.08333333,  0.05555556,  0.02777778,  0.02777778,\n",
       "          0.11111111,  0.11111111,  1.        ,  0.11111111,  0.        ,\n",
       "          0.08333333,  0.08333333,  0.05555556,  0.02777778],\n",
       "        [ 0.05555556,  0.02777778,  0.02777778,  0.02777778,  0.02777778,\n",
       "          0.05555556,  0.05555556,  0.02777778,  0.02777778,  0.02777778,\n",
       "          0.08333333,  0.        ,  0.        ,  0.        ,  0.08333333,\n",
       "          0.08333333,  0.16666667,  0.11111111,  1.        ,  0.        ,\n",
       "          0.11111111,  0.13888889,  0.05555556,  0.02777778],\n",
       "        [ 0.02777778,  0.        ,  0.02777778,  0.02777778,  0.02777778,\n",
       "          0.05555556,  0.02777778,  0.        ,  0.05555556,  0.05555556,\n",
       "          0.        ,  0.02777778,  0.05555556,  0.02777778,  0.02777778,\n",
       "          0.05555556,  0.        ,  0.        ,  0.        ,  1.        ,\n",
       "          0.        ,  0.        ,  0.08333333,  0.02777778],\n",
       "        [ 0.05555556,  0.        ,  0.02777778,  0.        ,  0.02777778,\n",
       "          0.05555556,  0.02777778,  0.02777778,  0.02777778,  0.08333333,\n",
       "          0.        ,  0.        ,  0.        ,  0.        ,  0.02777778,\n",
       "          0.08333333,  0.05555556,  0.08333333,  0.11111111,  0.        ,\n",
       "          1.        ,  0.11111111,  0.05555556,  0.02777778],\n",
       "        [ 0.02777778,  0.        ,  0.11111111,  0.        ,  0.        ,\n",
       "          0.05555556,  0.02777778,  0.        ,  0.02777778,  0.        ,\n",
       "          0.02777778,  0.        ,  0.02777778,  0.02777778,  0.02777778,\n",
       "          0.05555556,  0.11111111,  0.08333333,  0.13888889,  0.        ,\n",
       "          0.11111111,  1.        ,  0.05555556,  0.02777778],\n",
       "        [ 0.02777778,  0.05555556,  0.08333333,  0.02777778,  0.        ,\n",
       "          0.05555556,  0.        ,  0.02777778,  0.        ,  0.08333333,\n",
       "          0.        ,  0.        ,  0.        ,  0.        ,  0.02777778,\n",
       "          0.        ,  0.08333333,  0.05555556,  0.05555556,  0.08333333,\n",
       "          0.05555556,  0.05555556,  1.        ,  0.        ],\n",
       "        [ 0.05555556,  0.11111111,  0.        ,  0.05555556,  0.02777778,\n",
       "          0.19444444,  0.        ,  0.05555556,  0.08333333,  0.        ,\n",
       "          0.08333333,  0.02777778,  0.02777778,  0.05555556,  0.08333333,\n",
       "          0.19444444,  0.08333333,  0.02777778,  0.02777778,  0.02777778,\n",
       "          0.02777778,  0.02777778,  0.        ,  1.        ]])"
      ]
     },
     "execution_count": 553,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "JankyAssMatrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## taking a straight jaccard distance, the similarities seem low\n",
    "Conclusion: the order of those words are not similar...????"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 509,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#print JankyAssMatrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 510,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "# y_pred = ['a', 'b', 'b', 'b']\n",
    "# y_true = ['a', 'b', 'a', 'b']\n",
    "# jaccard_similarity_score(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#####but we can put it in a model too, circles\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 511,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAbQAAAEqCAYAAAB9WKV1AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nkUD4/+ETaXldXHlkAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x4634fea10>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "circle1=plt.Circle((0,0),.2,color='r')\n",
    "circle2=plt.Circle((.5,.5),.2,color='b')\n",
    "circle3=plt.Circle((1,1),.2,color='g',clip_on=False)\n",
    "fig = plt.gcf()\n",
    "fig.gca().add_artist(circle1)\n",
    "fig.gca().add_artist(circle2)\n",
    "fig.gca().add_artist(circle3)\n",
    "fig.savefig('plotcircles.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#ron's contractions\n",
    "dcontractions = {\"she'll\": ' she will', \"you'd\": ' you had', \"don't\": ' do not', \"didn't\": ' did not', 'yall': ' you all', \"they've\": ' they have', \"won't\": ' will not', \"we'd\": ' we had', \"couldn't\": ' could not', \"shan't\": ' shall not', \"doesn't\": ' does not', \"he's\": ' he is', \"it's\": ' it is', \"where's\": ' where is', \"he'd\": ' he had', \"there's\": ' there is', \"shouldn't\": ' should not', \"they'll\": ' they will', \"haven't\": ' have not', \"we're\": ' we are', \"who've\": ' who have', \"mightn't\": ' might not', \"what're\": ' what are', \"mustn't \": ' must not', \"you're\": ' you are', \"what's\": ' what is', \"who's\": ' who is', \"let's\": ' let us', \"they'd\": ' they had', \"what'll\": ' what will', \"I'd\": ' I had', \"you've\": ' you have', \"what've\": ' what have', \"hadn't\": ' had not', \"who'll\": ' who will', \"I'm\": ' I am', \"aren't\": ' are not', \"who'd\": ' who had', \"he'll\": ' he will', \"I'll\": ' I will', \"they're\": ' they are', \"weren't\": ' were not', \"wouldn't\": ' would not', \"I've\": ' I have', \"hasn't\": ' has not', \"she'd\": ' she had', \"you'll\": ' you will', \"can't\": ' cannot', \"we've\": ' we have', \"she's\": ' she is', \"ya'll\": ' you all', \"isn't\": ' is not', \"that's\": ' that is'}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 515,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#d=dict(JankyAssMatrix[ro])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 519,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# for row in JankyAssMatrix:\n",
    "#     for col in row:\n",
    "#         circle1=plt.Circle((0,0),.2,color='r')\n",
    "#         circle2=plt.Circle((1-(row),1-(col)),.2,color='b')\n",
    "#         circle3=plt.Circle((1,1),.2,color='g',clip_on=False)\n",
    "#         fig = plt.gcf()\n",
    "#         fig.gca().add_artist(circle1)\n",
    "#         fig.gca().add_artist(circle2)\n",
    "#         fig.gca().add_artist(circle3)\n",
    "#         fig.savefig('plotcircles.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "\n",
    "\n",
    "KMeans(n_clusters=8):\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#and a way to go through it\n",
    "#dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#to go through any body and say similar or dissimilar, we would expect bibles to be similar for instance\n",
    "#at the same time, its surprising to find dissimilar combinations of words.\n",
    "#so this says something about both the rhetoric, about particulars of arrangement, and \n",
    "#about general ways of going"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "takeaways,\n",
    "you "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 554,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[matrix([[ 0.]])],\n",
       " [matrix([[-1.]])],\n",
       " [matrix([[-0.97222222]])],\n",
       " [matrix([[-0.97222222]])],\n",
       " [matrix([[-0.97222222]])],\n",
       " [matrix([[-0.88888889]])],\n",
       " [matrix([[-1.]])],\n",
       " [matrix([[-1.]])],\n",
       " [matrix([[-0.94444444]])],\n",
       " [matrix([[-0.97222222]])],\n",
       " [matrix([[-0.97222222]])],\n",
       " [matrix([[-1.]])],\n",
       " [matrix([[-1.]])],\n",
       " [matrix([[-0.97222222]])],\n",
       " [matrix([[-1.]])],\n",
       " [matrix([[-0.88888889]])],\n",
       " [matrix([[-0.94444444]])],\n",
       " [matrix([[-0.88888889]])],\n",
       " [matrix([[-0.94444444]])],\n",
       " [matrix([[-0.97222222]])],\n",
       " [matrix([[-0.94444444]])],\n",
       " [matrix([[-0.97222222]])],\n",
       " [matrix([[-0.97222222]])],\n",
       " [matrix([[-0.94444444]])]]"
      ]
     },
     "execution_count": 554,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[[i-1] for i in JankyAssMatrix[:,0]]\n",
    "#0, -1, -.97, -.88, -.94, "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These are so specific as to have some use on their own. There's a reason they're this way? Perhaps put at industry-specific distance, e.g."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 535,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[36 66 96]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "mymatrix = np.matrix([[11,12,13],\n",
    "                      [21,22,23],\n",
    "                      [31,32,33]])\n",
    "def myfunction( x ):\n",
    "    return sum(x)\n",
    "\n",
    "print np.apply_along_axis( myfunction, axis=1, arr=mymatrix )\n",
    "#[36 66 96]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "There are only "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 483,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#!pip install wordcloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 536,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'function' object is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-536-536ef2b1353f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mcolumn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmatrix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mrow\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmatrix\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mcolumn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtable\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-536-536ef2b1353f>\u001b[0m in \u001b[0;36mcolumn\u001b[0;34m(matrix, i)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mcolumn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmatrix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mrow\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmatrix\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mcolumn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtable\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'function' object is not iterable"
     ]
    }
   ],
   "source": [
    "def column(matrix, i):\n",
    "    return [row[i-1] for row in matrix]\n",
    "column(table,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from os import path\n",
    "from wordcloud import WordCloud\n",
    "\n",
    "d = path.dirname(__file__)\n",
    "\n",
    "# Read the whole text.\n",
    "text = open(path.join(d, 'constitution.txt')).read()\n",
    "\n",
    "# Generate a word cloud image\n",
    "wordcloud = WordCloud().generate(text)\n",
    "\n",
    "# Display the generated image:\n",
    "# the matplotlib way:\n",
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(wordcloud)\n",
    "plt.axis(\"off\")\n",
    "\n",
    "# take relative word frequencies into account, lower max_font_size\n",
    "wordcloud = WordCloud(max_font_size=40, relative_scaling=.5).generate(text)\n",
    "plt.figure()\n",
    "plt.imshow(wordcloud)\n",
    "plt.axis(\"off\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cv_genesis[name] = (vectorizer, vectorized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 432,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ylt_lda_model = lda_topic_model(count_vectorized_bibles['Young\\'s Literal Translation'][1])\n",
    "lda_bible_models['Young\\'s Literal Translation'] = ylt_lda_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 2/24 [01:26<15:40, 42.74s/it]WARNING:lda:all zero row in document-term matrix found\n",
      "WARNING:lda:all zero row in document-term matrix found\n",
      "WARNING:lda:all zero row in document-term matrix found\n",
      "WARNING:lda:all zero row in document-term matrix found\n",
      "WARNING:lda:all zero row in document-term matrix found\n"
     ]
    }
   ],
   "source": [
    "lda_bible_models = {}\n",
    "for name in tqdm(version_names):\n",
    "    lda_model = lda_topic_model(count_vectorized_bibles[name][1])\n",
    "    lda_bible_models[name] = lda_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('lda_models.pkl', 'w') as picklefile:\n",
    "    pickle.dump(lda_bible_models, picklefile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "lda_models_test = lda_topic_model(\n",
    "    count_vectorized_bibles['New International Version'][1], range(6,8,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "# lda_models_test_just_fit_no_transform = lda_topic_model(\n",
    "#     count_vectorized_bibles['New International Version'][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 477,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def view_topics(bible_topic_models, vectorizer):\n",
    "    topwords = {}\n",
    "    for numtopics, model in bible_topic_models.items():\n",
    "        topic_word = model.topic_word_  # model.components_ also works\n",
    "        n_top_words = 12\n",
    "        key = numtopics\n",
    "        values = []\n",
    "        for i, topic_dist in enumerate(topic_word):\n",
    "            topic_words = np.array(vectorizer.get_feature_names())[np.argsort(topic_dist)][:-(n_top_words+1):-1]\n",
    "            values.append('Topic {}: {}'.format(i, ' '.join(topic_words)))\n",
    "        topwords[key] = values\n",
    "    return topwords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Second Really Interesting Thing:\n",
    "structural homologies: top topics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(\"lda_models.pkl\", 'r') as picklefile: \n",
    "    lda_models = pickle.load(picklefile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 435,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Topics: 1\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index 7932 is out of bounds for axis 1 with size 7932",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-435-8b163724e437>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m view_topics(lda_models['Young\\'s Literal Translation'], \n\u001b[0;32m----> 2\u001b[0;31m             count_vectorized_bibles['Young\\'s Literal Translation'][0])\n\u001b[0m",
      "\u001b[0;32m<ipython-input-433-b72d0d0268cb>\u001b[0m in \u001b[0;36mview_topics\u001b[0;34m(bible_topic_models, vectorizer)\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0;32mprint\u001b[0m \u001b[0;34m'Number of Topics:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumtopics\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtopic_dist\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtopic_word\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m             \u001b[0mtopic_words\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvectorizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_feature_names\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margsort\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtopic_dist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_top_words\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m             \u001b[0;32mprint\u001b[0m \u001b[0;34m'Topic {}: {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m' '\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtopic_words\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0;32mprint\u001b[0m \u001b[0;34m'\\n'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: index 7932 is out of bounds for axis 1 with size 7932"
     ]
    }
   ],
   "source": [
    "view_topics(lda_models['Young\\'s Literal Translation'], \n",
    "            count_vectorized_bibles['Young\\'s Literal Translation'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 434,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hebrew Names Version\n",
      "Number of Topics: 1\n",
      "Topic 0: lord god yisrael son man one king house people children land day\n",
      "\n",
      "\n",
      "Number of Topics: 2\n",
      "Topic 0: lord god man land day people yisrael let one says like eretz\n",
      "Topic 1: son king god yisrael children one father men house also david yeshua\n",
      "\n",
      "\n",
      "Number of Topics: 3\n",
      "Topic 0: lord land people yisrael says god day one house moshe eretz offering\n",
      "Topic 1: king son yisrael lord children david house sons men people yehudah father\n",
      "Topic 2: god man dont lord also things one let us yeshua therefore may\n",
      "\n",
      "\n",
      "Number of Topics: 4\n",
      "Topic 0: lord god land says people eretz let day like hand man behold\n",
      "Topic 1: lord one moshe offering two house children kohen yisrael altar tent seven\n",
      "Topic 2: king son yisrael lord david children people house sons men father yehudah\n",
      "Topic 3: god one man things yeshua also dont us therefore good know may\n",
      "\n",
      "\n",
      "Number of Topics: 5\n",
      "Topic 0: lord one offering kohen two holy altar moshe tent gold burnt side\n",
      "Topic 1: lord god says like eretz let man heart thus dont nations neither\n",
      "Topic 2: king son david children yisrael house sons yehudah father yerushalayim hundred kings\n",
      "Topic 3: lord yisrael god land people go saying us day hand behold man\n",
      "Topic 4: god one things yeshua also man dont us therefore messiah good may\n",
      "\n",
      "\n",
      "Good News Translation\n",
      "Number of Topics: 1\n",
      "Topic 0: lord people god cross one king israel like us jesus son go\n",
      "\n",
      "\n",
      "Number of Topics: 2\n",
      "Topic 0: lord king people israel son land men city one temple jerusalem go\n",
      "Topic 1: god lord people cross one like jesus us know gods may say\n",
      "\n",
      "\n",
      "Number of Topics: 3\n",
      "Topic 0: lord god people cross like one us gods know live good let\n",
      "Topic 1: jesus king son man men go david answered father one told sent\n",
      "Topic 2: lord israel people temple moses king land cross judah one christ put\n",
      "\n",
      "\n",
      "Number of Topics: 4\n",
      "Topic 0: king lord israel people city david judah son jerusalem kings land men\n",
      "Topic 1: god cross jesus people one us know good say gods life christ\n",
      "Topic 2: man answered one go two asked son saw back took told men\n",
      "Topic 3: lord people god like cross israel land day moses one live may\n",
      "\n",
      "\n",
      "Number of Topics: 5\n",
      "Topic 0: lord people god like land cross israel us let one live hebrew\n",
      "Topic 1: go man answered told one back asked saw would men us sent\n",
      "Topic 2: god cross jesus people one gods us christ good know life things\n",
      "Topic 3: king son israel david people lord judah men kings sons city temple\n",
      "Topic 4: lord moses cross people must offering day one altar put ex priest\n",
      "\n",
      "\n",
      "GOD'S WORD Translation\n",
      "Number of Topics: 1\n",
      "Topic 0: lord people god one king son israel like jesus dont us go\n",
      "\n",
      "\n",
      "Number of Topics: 2\n",
      "Topic 0: lord king israel son land people men must david jerusalem lords moses\n",
      "Topic 1: people god lord one jesus like dont us person father man know\n",
      "\n",
      "\n",
      "Number of Topics: 3\n",
      "Topic 0: lord people must go day one land take man god like bring\n",
      "Topic 1: king son israel david men temple judah sons lord descendants father lords\n",
      "Topic 2: god people jesus one us like dont person gods good life lord\n",
      "\n",
      "\n",
      "Number of Topics: 4\n",
      "Topic 0: lord people god like land let one live israel earth says go\n",
      "Topic 1: king son israel men david judah took lord told sons city father\n",
      "Topic 2: must lord moses holy offering offerings day tent priest gold one temple\n",
      "Topic 3: god jesus people one dont person man gods good us life know\n",
      "\n",
      "\n",
      "Number of Topics: 5\n",
      "Topic 0: lord people like god one land earth let away says live nations\n",
      "Topic 1: king israel son lord david judah men people jerusalem city kings temple\n",
      "Topic 2: jesus man told one father son asked go back people saw god\n",
      "Topic 3: lord must moses offering sons holy israelites priest offerings land tent lords\n",
      "Topic 4: god people person gods good dont life us christ things one way\n",
      "\n",
      "\n",
      "King James Version\n",
      "Number of Topics: 1\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index 9356 is out of bounds for axis 1 with size 9355",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-434-33396181747f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodels\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlda_models\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0;32mprint\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mview_topics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcount_vectorized_bibles\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-433-b72d0d0268cb>\u001b[0m in \u001b[0;36mview_topics\u001b[0;34m(bible_topic_models, vectorizer)\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0;32mprint\u001b[0m \u001b[0;34m'Number of Topics:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumtopics\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtopic_dist\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtopic_word\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m             \u001b[0mtopic_words\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvectorizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_feature_names\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margsort\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtopic_dist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_top_words\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m             \u001b[0;32mprint\u001b[0m \u001b[0;34m'Topic {}: {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m' '\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtopic_words\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0;32mprint\u001b[0m \u001b[0;34m'\\n'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: index 9356 is out of bounds for axis 1 with size 9355"
     ]
    }
   ],
   "source": [
    "for name, models in lda_models.items():\n",
    "    print name\n",
    "    view_topics(models, count_vectorized_bibles[name][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "##same thing as above cell\n",
    "# for name, models in lda_bible_models.items():\n",
    "#     print name\n",
    "#     view_topics(models, count_vectorized_bibles[name][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#pyLDAvis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 394,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#!pip install pyldavis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "count_vectorized_bibles[name] = (vectorizer, vectorized)\n",
    "counts_dfs #vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 396,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pyLDAvis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# prepare pyLDAvis stuff \n",
    "get_normed = lambda data: pd.DataFrame(data).div(data.sum(axis = 1), axis = 0) \n",
    "prepared = pyLDAvis.prepare(\n",
    "        doc_lengths = docs.str.len(),\n",
    "        vocab = vocab,\n",
    "        term_frequency = np.asarray(matrix.sum(axis = 0)).ravel().tolist(),\n",
    "        topic_term_dists = get_normed(lda.components_),  \n",
    "        doc_topic_dists = get_normed(doc_topic_dists)) \n",
    "\n",
    "return prepared) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def prep_pylda(docs, n_topics = 5):   \n",
    "    vect = TfidfVectorizer(max_df = 0.5, max_features = 10000,\n",
    "                                 min_df = 5, stop_words = STOPWORDS,\n",
    "                                 use_idf = True, tokenizer = None, ngram_range=(1, 3))\n",
    "    matrix = vect.fit_transform(docs)\n",
    "    vocab = vect.get_feature_names()\n",
    "    \n",
    "    # fit transform lda\n",
    "    lda = LatentDirichletAllocation(n_topics=n_topics, max_iter=5,\n",
    "                learning_method='online', learning_offset=50.,\n",
    "                random_state=0, doc_topic_prior = .001)\n",
    "    doc_topic_dists = lda.fit_transform(matrix)\n",
    "    \n",
    "    # prepare pyLDAvis stuff \n",
    "    get_normed = lambda data: pd.DataFrame(data).div(data.sum(axis = 1), axis = 0) \n",
    "    prepared = pyLDAvis.prepare(\n",
    "            doc_lengths = docs.str.len(),\n",
    "            vocab = vocab,\n",
    "            term_frequency = np.asarray(matrix.sum(axis = 0)).ravel().tolist(),\n",
    "            topic_term_dists = get_normed(lda.components_),  \n",
    "            doc_topic_dists = get_normed(doc_topic_dists)) \n",
    "    \n",
    "    return prepared"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# display in notebook\n",
    "pyLDAvis.display(prepared)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1189, 10364)"
      ]
     },
     "execution_count": 278,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_vectorized_bibles['New International Version'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8056"
      ]
     },
     "execution_count": 282,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(np.array(vectorizer.get_feature_names()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vectorizer length: 10364\n",
      "vectorized matrix shape: (1189, 10364)\n",
      "vectorizer length: 8101\n",
      "vectorized matrix shape: (1189, 8101)\n",
      "vectorizer length: 8042\n",
      "vectorized matrix shape: (1189, 8042)\n",
      "vectorizer length: 8478\n",
      "vectorized matrix shape: (1189, 8478)\n",
      "vectorizer length: 9364\n",
      "vectorized matrix shape: (1189, 9364)\n",
      "vectorizer length: 10020\n",
      "vectorized matrix shape: (1189, 10020)\n",
      "vectorizer length: 8105\n",
      "vectorized matrix shape: (1189, 8105)\n",
      "vectorizer length: 12312\n",
      "vectorized matrix shape: (1189, 12312)\n",
      "vectorizer length: 4312\n",
      "vectorized matrix shape: (1189, 4312)\n",
      "vectorizer length: 8826\n",
      "vectorized matrix shape: (1189, 8826)\n",
      "vectorizer length: 8201\n",
      "vectorized matrix shape: (1189, 8201)\n",
      "vectorizer length: 10100\n",
      "vectorized matrix shape: (1189, 10100)\n",
      "vectorizer length: 10459\n",
      "vectorized matrix shape: (1189, 10459)\n",
      "vectorizer length: 8972\n",
      "vectorized matrix shape: (1189, 8972)\n",
      "vectorizer length: 6575\n",
      "vectorized matrix shape: (1189, 6575)\n",
      "vectorizer length: 6133\n",
      "vectorized matrix shape: (1189, 6133)\n",
      "vectorizer length: 8105\n",
      "vectorized matrix shape: (1189, 8105)\n",
      "vectorizer length: 9551\n",
      "vectorized matrix shape: (1189, 9551)\n",
      "vectorizer length: 10070\n",
      "vectorized matrix shape: (1189, 10070)\n",
      "vectorizer length: 8295\n",
      "vectorized matrix shape: (1189, 8295)\n",
      "vectorizer length: 11521\n",
      "vectorized matrix shape: (1189, 11521)\n",
      "vectorizer length: 9535\n",
      "vectorized matrix shape: (1189, 9535)\n",
      "vectorizer length: 7939\n",
      "vectorized matrix shape: (1189, 7939)\n",
      "vectorizer length: 10098\n",
      "vectorized matrix shape: (1189, 10098)\n",
      "vectorizer length: 9293\n",
      "vectorized matrix shape: (1189, 9293)\n",
      "vectorizer length: 8136\n",
      "vectorized matrix shape: (1189, 8136)\n",
      "vectorizer length: 8056\n",
      "vectorized matrix shape: (1189, 8056)\n"
     ]
    }
   ],
   "source": [
    "for vectorizer, vectorized in count_vectorized_bibles.values():\n",
    "    print 'vectorizer length:', len(np.array(vectorizer.get_feature_names()))\n",
    "    print 'vectorized matrix shape:', vectorized.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Topics: 2\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index 10148 is out of bounds for axis 1 with size 10098",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-332-0233b9260dac>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mview_topics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlda_models_test_just_fit_no_transform\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcount_vectorized_bibles\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Lexham English Bible'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-274-cb55b4f943bc>\u001b[0m in \u001b[0;36mview_topics\u001b[0;34m(bible_topic_models, vectorizer)\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0;32mprint\u001b[0m \u001b[0;34m'Number of Topics:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumtopics\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtopic_dist\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtopic_word\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m             \u001b[0mtopic_words\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvectorizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_feature_names\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margsort\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtopic_dist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_top_words\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m             \u001b[0;32mprint\u001b[0m \u001b[0;34m'Topic {}: {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m' '\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtopic_words\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0;32mprint\u001b[0m \u001b[0;34m'\\n'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: index 10148 is out of bounds for axis 1 with size 10098"
     ]
    }
   ],
   "source": [
    "view_topics(lda_models_test_just_fit_no_transform, count_vectorized_bibles['Lexham English Bible'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{6: <lda.lda.LDA instance at 0x2ef1a3290>}"
      ]
     },
     "execution_count": 304,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lda_models_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<1189x10364 sparse matrix of type '<type 'numpy.int64'>'\n",
       "\twith 226272 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 267,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_vectorized_bibles['New International Version']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#### RUN THIS OVERNIGHT ###\n",
    "# lda_topics_by_bible_version = {}\n",
    "# for name in tqdm(versions.keys()):\n",
    "#     lda_models = lda_topic_model(count_vectorized_bibles[name])\n",
    "#     lda_topics_by_bible_version[name] = lda_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/7 [00:00<?, ?it/s]WARNING:lda:all zero row in document-term matrix found\n",
      " 14%|█▍        | 1/7 [00:40<04:05, 40.90s/it]WARNING:lda:all zero row in document-term matrix found\n",
      " 29%|██▊       | 2/7 [01:32<03:40, 44.13s/it]WARNING:lda:all zero row in document-term matrix found\n",
      " 43%|████▎     | 3/7 [02:31<03:14, 48.63s/it]WARNING:lda:all zero row in document-term matrix found\n",
      " 57%|█████▋    | 4/7 [03:43<02:46, 55.65s/it]WARNING:lda:all zero row in document-term matrix found\n",
      " 71%|███████▏  | 5/7 [05:07<02:08, 64.24s/it]WARNING:lda:all zero row in document-term matrix found\n",
      " 86%|████████▌ | 6/7 [06:29<01:09, 69.53s/it]WARNING:lda:all zero row in document-term matrix found\n"
     ]
    }
   ],
   "source": [
    "bible_topic_models = lda_topic_model(vecs_bible)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(24609, 13400)\n",
      "315439\n"
     ]
    }
   ],
   "source": [
    "print vecs_bible.shape\n",
    "print vecs_bible.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:lda:all zero row in document-term matrix found\n",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tqdm._tqdm.tqdm at 0x104916210>"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(vecs_bible)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2, 4, 6, 8, 10, 12, 14]"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bible_topic_models.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Topics: 2\n",
      "Topic 0: lord god man hath come let us people\n",
      "Topic 1: king lord son israel came children house went\n",
      "\n",
      "\n",
      "Number of Topics: 4\n",
      "Topic 0: lord god israel people hath land o saith\n",
      "Topic 1: god man jesus things one hath also lord\n",
      "Topic 2: earth man every like behold shalt thereof forth\n",
      "Topic 3: king son israel lord children came sons house\n",
      "\n",
      "\n",
      "Number of Topics: 6\n",
      "Topic 0: lord god hath o saith people shalt israel\n",
      "Topic 1: came went lord israel king people david land\n",
      "Topic 2: earth man like hath every behold forth come\n",
      "Topic 3: god man jesus things one hath also us\n",
      "Topic 4: son king sons children israel years house judah\n",
      "Topic 5: lord offering one house made shalt thereof gold\n",
      "\n",
      "\n",
      "Number of Topics: 8\n",
      "Topic 0: lord god o heart let hath man mine\n",
      "Topic 1: son children king sons israel hundred judah years\n",
      "Topic 2: earth thereof like made one gold sea great\n",
      "Topic 3: lord god israel land saith people hath thus\n",
      "Topic 4: man father shalt eat go hath let take\n",
      "Topic 5: god things man jesus christ also one hath\n",
      "Topic 6: came king went david saying people house lord\n",
      "Topic 7: lord offering moses day israel priest one aaron\n",
      "\n",
      "\n",
      "Number of Topics: 10\n",
      "Topic 0: lord god israel land children moses people us\n",
      "Topic 1: lord god o hath earth heart let hear\n",
      "Topic 2: king lord house israel came god judah saith\n",
      "Topic 3: eat man every bread drink water flesh shalt\n",
      "Topic 4: god things jesus man christ also one us\n",
      "Topic 5: came went david man saying behold saul saw\n",
      "Topic 6: land sea city cities went thereof people even\n",
      "Topic 7: son sons children years hundred thousand israel men\n",
      "Topic 8: lord man hand hath shalt mine away saith\n",
      "Topic 9: offering lord one made gold two altar shalt\n",
      "\n",
      "\n",
      "Number of Topics: 12\n",
      "Topic 0: earth lord like heaven day great come waters\n",
      "Topic 1: land every eat lord saith shalt man also\n",
      "Topic 2: son sons years hundred children thousand two three\n",
      "Topic 3: god things christ jesus also hath us one\n",
      "Topic 4: house gold one thereof made two silver put\n",
      "Topic 5: children israel land came went cities people mount\n",
      "Topic 6: man let go come say us shalt one\n",
      "Topic 7: lord god o man heart let mine hath\n",
      "Topic 8: lord god israel people saith land hath thus\n",
      "Topic 9: came went jesus saw man saying behold took\n",
      "Topic 10: king david came son israel lord house judah\n",
      "Topic 11: lord offering moses day burnt priest aaron shalt\n",
      "\n",
      "\n",
      "Number of Topics: 14\n",
      "Topic 0: god things christ also us hath one jesus\n",
      "Topic 1: lord god israel saying land people word saith\n",
      "Topic 2: lord saith come go land thus shalt people\n",
      "Topic 3: lord god o name ever hath people let\n",
      "Topic 4: went israel came children land people men city\n",
      "Topic 5: king years israel thousand judah hundred men jerusalem\n",
      "Topic 6: earth lord like fire great behold hath day\n",
      "Topic 7: eat every water man drink bread flesh wine\n",
      "Topic 8: jesus came saying man come went things disciples\n",
      "Topic 9: man heart hath let evil god wicked soul\n",
      "Topic 10: david came father king man son saul saying\n",
      "Topic 11: son sons children tribe begat brethren levites israel\n",
      "Topic 12: house gold made one thereof two silver side\n",
      "Topic 13: lord offering moses day burnt priest shalt one\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for numtopics, model in bible_topic_models.items():\n",
    "    topic_word = model.topic_word_  # model.components_ also works\n",
    "    n_top_words = 8\n",
    "    print 'Number of Topics:', numtopics\n",
    "    for i, topic_dist in enumerate(topic_word):\n",
    "        topic_words = np.array(vectorizer.get_feature_names())[np.argsort(topic_dist)][:-(n_top_words+1):-1]\n",
    "        print 'Topic {}: {}'.format(i, ' '.join(topic_words))\n",
    "    print '\\n'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic 0: jesus came saying man went come disciples 21\n",
      "Topic 1: lord day house god israel people every days\n",
      "Topic 2: gold thereof one made two silver house side\n",
      "Topic 3: like forth thereof fruit tree every fire high\n",
      "Topic 4: lord god saying word hear hath words saith\n",
      "Topic 5: lord god ever name praise hath let earth\n",
      "Topic 6: eat bread water 13 flesh drink 11 wine\n",
      "Topic 7: king son judah israel house came jerusalem babylon\n",
      "Topic 8: god christ things also jesus us hath one\n",
      "Topic 9: lord offering moses aaron burnt altar priest one\n",
      "Topic 10: let us go come lord may saying god\n",
      "Topic 11: man heart evil good wicked wise 10 god\n",
      "Topic 12: shalt man hath 18 21 22 hand put\n",
      "Topic 13: children israel land cities 15 21 side 19\n",
      "Topic 14: son sons years hundred thousand children two begat\n",
      "Topic 15: david came went men king saul people israel\n",
      "Topic 16: mine hath let time day enemies lord soul\n",
      "Topic 17: lord land god saith israel thus people egypt\n",
      "Topic 18: earth heaven great waters like sea 10 fire\n",
      "Topic 19: father son jacob wife name sons abraham came\n"
     ]
    }
   ],
   "source": [
    "topic_word = model.topic_word_  # model.components_ also works\n",
    "n_top_words = 8\n",
    "for i, topic_dist in enumerate(topic_word):\n",
    "    topic_words = np.array(vectorizer.get_feature_names())[np.argsort(topic_dist)][:-(n_top_words+1):-1]\n",
    "    print('Topic {}: {}'.format(i, ' '.join(topic_words)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#on to clustering!\n",
    "##### k-means/k++\n",
    "class sklearn.cluster.KMeans(n_clusters=8, init='k-means++', n_init=10, max_iter=300, tol=0.0001, precompute_distances='auto', verbose=0, random_state=None, copy_x=True, n_jobs=1)\n",
    "\n",
    "\n",
    "#####hierarchical \n",
    "- would probs be good b/c bible is 'hierarchical'- there are many obscure characters that only appear once AND many common words\n",
    "class sklearn.cluster.Ward(n_clusters=2, memory=Memory(cachedir=None), connectivity=None, n_components=None, compute_full_tree='auto', pooling_func=<function mean at 0x2b8085912398>)\n",
    "\n",
    "\n",
    "#####DBScan\n",
    "- how to define epsilon?\n",
    "- may not work b/cclusters may not be same size\n",
    "\n",
    "#####mean shift\n",
    "\n",
    "#####spectral\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 406,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.cluster import AgglomerativeClustering\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn\n",
    "from sklearn.neighbors import kneighbors_graph\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "AgglomerativeClustering(n_clusters=2, affinity='euclidean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_values = count_vectorized_bibles['American Standard Version'][1].toarray()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#plot variance for each value for 'k' between 1,10\n",
    "initial = [cluster.vq.kmeans(tests,i) for i in range(1,10)]\n",
    "pyplot.plot([var for (cent,var) in initial])\n",
    "pyplot.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 397,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.cluster import Ward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 401,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def old_or_new_testament(count_vectorized_bibles):\n",
    "    old_or_new_test = {}\n",
    "    #hierarchical_clusters = {}\n",
    "    for name, values in tqdm(count_vectorized_bibles.items()):\n",
    "        vecs_array = values[1].toarray()\n",
    "        model = Ward(n_clusters=2)\n",
    "        labels = model.fit_predict(vecs_array)\n",
    "        old_or_new_test[name] = labels\n",
    "    return old_or_new_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 412,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1189,)"
      ]
     },
     "execution_count": 412,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "old_or_new_test['American Standard Version'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 402,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/24 [00:00<?, ?it/s]/Users/Ben/anaconda/anaconda/lib/python2.7/site-packages/sklearn/cluster/hierarchical.py:938: DeprecationWarning: The Ward class is deprecated since 0.14 and will be removed in 0.17. Use the AgglomerativeClustering instead.\n",
      "  \"instead.\", DeprecationWarning)\n",
      "  4%|▍         | 1/24 [00:07<02:43,  7.12s/it]/Users/Ben/anaconda/anaconda/lib/python2.7/site-packages/sklearn/cluster/hierarchical.py:938: DeprecationWarning: The Ward class is deprecated since 0.14 and will be removed in 0.17. Use the AgglomerativeClustering instead.\n",
      "  \"instead.\", DeprecationWarning)\n",
      "  8%|▊         | 2/24 [00:13<02:33,  6.98s/it]/Users/Ben/anaconda/anaconda/lib/python2.7/site-packages/sklearn/cluster/hierarchical.py:938: DeprecationWarning: The Ward class is deprecated since 0.14 and will be removed in 0.17. Use the AgglomerativeClustering instead.\n",
      "  \"instead.\", DeprecationWarning)\n",
      " 12%|█▎        | 3/24 [00:21<02:28,  7.07s/it]/Users/Ben/anaconda/anaconda/lib/python2.7/site-packages/sklearn/cluster/hierarchical.py:938: DeprecationWarning: The Ward class is deprecated since 0.14 and will be removed in 0.17. Use the AgglomerativeClustering instead.\n",
      "  \"instead.\", DeprecationWarning)\n",
      " 17%|█▋        | 4/24 [00:29<02:27,  7.35s/it]/Users/Ben/anaconda/anaconda/lib/python2.7/site-packages/sklearn/cluster/hierarchical.py:938: DeprecationWarning: The Ward class is deprecated since 0.14 and will be removed in 0.17. Use the AgglomerativeClustering instead.\n",
      "  \"instead.\", DeprecationWarning)\n",
      " 21%|██        | 5/24 [00:37<02:23,  7.55s/it]/Users/Ben/anaconda/anaconda/lib/python2.7/site-packages/sklearn/cluster/hierarchical.py:938: DeprecationWarning: The Ward class is deprecated since 0.14 and will be removed in 0.17. Use the AgglomerativeClustering instead.\n",
      "  \"instead.\", DeprecationWarning)\n",
      " 25%|██▌       | 6/24 [00:44<02:12,  7.36s/it]/Users/Ben/anaconda/anaconda/lib/python2.7/site-packages/sklearn/cluster/hierarchical.py:938: DeprecationWarning: The Ward class is deprecated since 0.14 and will be removed in 0.17. Use the AgglomerativeClustering instead.\n",
      "  \"instead.\", DeprecationWarning)\n",
      " 29%|██▉       | 7/24 [00:51<02:05,  7.39s/it]/Users/Ben/anaconda/anaconda/lib/python2.7/site-packages/sklearn/cluster/hierarchical.py:938: DeprecationWarning: The Ward class is deprecated since 0.14 and will be removed in 0.17. Use the AgglomerativeClustering instead.\n",
      "  \"instead.\", DeprecationWarning)\n",
      " 33%|███▎      | 8/24 [00:55<01:41,  6.36s/it]/Users/Ben/anaconda/anaconda/lib/python2.7/site-packages/sklearn/cluster/hierarchical.py:938: DeprecationWarning: The Ward class is deprecated since 0.14 and will be removed in 0.17. Use the AgglomerativeClustering instead.\n",
      "  \"instead.\", DeprecationWarning)\n",
      " 38%|███▊      | 9/24 [01:01<01:36,  6.42s/it]/Users/Ben/anaconda/anaconda/lib/python2.7/site-packages/sklearn/cluster/hierarchical.py:938: DeprecationWarning: The Ward class is deprecated since 0.14 and will be removed in 0.17. Use the AgglomerativeClustering instead.\n",
      "  \"instead.\", DeprecationWarning)\n",
      " 42%|████▏     | 10/24 [01:08<01:30,  6.50s/it]/Users/Ben/anaconda/anaconda/lib/python2.7/site-packages/sklearn/cluster/hierarchical.py:938: DeprecationWarning: The Ward class is deprecated since 0.14 and will be removed in 0.17. Use the AgglomerativeClustering instead.\n",
      "  \"instead.\", DeprecationWarning)\n",
      " 46%|████▌     | 11/24 [01:16<01:30,  6.99s/it]/Users/Ben/anaconda/anaconda/lib/python2.7/site-packages/sklearn/cluster/hierarchical.py:938: DeprecationWarning: The Ward class is deprecated since 0.14 and will be removed in 0.17. Use the AgglomerativeClustering instead.\n",
      "  \"instead.\", DeprecationWarning)\n",
      " 50%|█████     | 12/24 [01:24<01:27,  7.32s/it]/Users/Ben/anaconda/anaconda/lib/python2.7/site-packages/sklearn/cluster/hierarchical.py:938: DeprecationWarning: The Ward class is deprecated since 0.14 and will be removed in 0.17. Use the AgglomerativeClustering instead.\n",
      "  \"instead.\", DeprecationWarning)\n",
      " 54%|█████▍    | 13/24 [01:32<01:20,  7.32s/it]/Users/Ben/anaconda/anaconda/lib/python2.7/site-packages/sklearn/cluster/hierarchical.py:938: DeprecationWarning: The Ward class is deprecated since 0.14 and will be removed in 0.17. Use the AgglomerativeClustering instead.\n",
      "  \"instead.\", DeprecationWarning)\n",
      " 58%|█████▊    | 14/24 [01:37<01:07,  6.77s/it]/Users/Ben/anaconda/anaconda/lib/python2.7/site-packages/sklearn/cluster/hierarchical.py:938: DeprecationWarning: The Ward class is deprecated since 0.14 and will be removed in 0.17. Use the AgglomerativeClustering instead.\n",
      "  \"instead.\", DeprecationWarning)\n",
      " 62%|██████▎   | 15/24 [01:42<00:56,  6.30s/it]/Users/Ben/anaconda/anaconda/lib/python2.7/site-packages/sklearn/cluster/hierarchical.py:938: DeprecationWarning: The Ward class is deprecated since 0.14 and will be removed in 0.17. Use the AgglomerativeClustering instead.\n",
      "  \"instead.\", DeprecationWarning)\n",
      " 67%|██████▋   | 16/24 [01:49<00:51,  6.40s/it]/Users/Ben/anaconda/anaconda/lib/python2.7/site-packages/sklearn/cluster/hierarchical.py:938: DeprecationWarning: The Ward class is deprecated since 0.14 and will be removed in 0.17. Use the AgglomerativeClustering instead.\n",
      "  \"instead.\", DeprecationWarning)\n",
      " 71%|███████   | 17/24 [01:56<00:45,  6.48s/it]/Users/Ben/anaconda/anaconda/lib/python2.7/site-packages/sklearn/cluster/hierarchical.py:938: DeprecationWarning: The Ward class is deprecated since 0.14 and will be removed in 0.17. Use the AgglomerativeClustering instead.\n",
      "  \"instead.\", DeprecationWarning)\n",
      " 75%|███████▌  | 18/24 [02:05<00:43,  7.28s/it]/Users/Ben/anaconda/anaconda/lib/python2.7/site-packages/sklearn/cluster/hierarchical.py:938: DeprecationWarning: The Ward class is deprecated since 0.14 and will be removed in 0.17. Use the AgglomerativeClustering instead.\n",
      "  \"instead.\", DeprecationWarning)\n",
      " 79%|███████▉  | 19/24 [02:12<00:36,  7.38s/it]/Users/Ben/anaconda/anaconda/lib/python2.7/site-packages/sklearn/cluster/hierarchical.py:938: DeprecationWarning: The Ward class is deprecated since 0.14 and will be removed in 0.17. Use the AgglomerativeClustering instead.\n",
      "  \"instead.\", DeprecationWarning)\n",
      " 83%|████████▎ | 20/24 [02:19<00:28,  7.08s/it]/Users/Ben/anaconda/anaconda/lib/python2.7/site-packages/sklearn/cluster/hierarchical.py:938: DeprecationWarning: The Ward class is deprecated since 0.14 and will be removed in 0.17. Use the AgglomerativeClustering instead.\n",
      "  \"instead.\", DeprecationWarning)\n",
      " 88%|████████▊ | 21/24 [02:27<00:22,  7.43s/it]/Users/Ben/anaconda/anaconda/lib/python2.7/site-packages/sklearn/cluster/hierarchical.py:938: DeprecationWarning: The Ward class is deprecated since 0.14 and will be removed in 0.17. Use the AgglomerativeClustering instead.\n",
      "  \"instead.\", DeprecationWarning)\n",
      " 92%|█████████▏| 22/24 [02:37<00:16,  8.07s/it]/Users/Ben/anaconda/anaconda/lib/python2.7/site-packages/sklearn/cluster/hierarchical.py:938: DeprecationWarning: The Ward class is deprecated since 0.14 and will be removed in 0.17. Use the AgglomerativeClustering instead.\n",
      "  \"instead.\", DeprecationWarning)\n",
      " 96%|█████████▌| 23/24 [02:44<00:07,  7.76s/it]/Users/Ben/anaconda/anaconda/lib/python2.7/site-packages/sklearn/cluster/hierarchical.py:938: DeprecationWarning: The Ward class is deprecated since 0.14 and will be removed in 0.17. Use the AgglomerativeClustering instead.\n",
      "  \"instead.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "old_or_new_test = old_or_new_testament(count_vectorized_bibles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# scatter plot\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(111)\n",
    "    #ax.scatter(X[:,2],X[:,1], s=30, c=cIdx[k])\n",
    "    clr = ['b','g','r','c','m','y','k']\n",
    "    for i in range(K[kIdx]):\n",
    "        ind = (cIdx[kIdx]==i)\n",
    "        ax.scatter(X[ind,4],X[ind,3], s=30, c=clr[i], label='Cluster %d'%i)\n",
    "    plt.xlabel('x')\n",
    "    plt.ylabel('y')\n",
    "    plt.title('Censored Tweet Clusters with K=%d' % K[kIdx])\n",
    "    plt.legend()\n",
    "    \n",
    "plot_kmeans(weibo.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 410,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Expected n_neighbors <= 1. Got 31",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-410-cd2fe005b2eb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mold_or_new_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mknn_graph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkneighbors_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m30\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minclude_self\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     plt.scatter(X[:, 0], X[:, 1], c=model.labels_,\n\u001b[1;32m      5\u001b[0m                 cmap=plt.cm.spectral)\n",
      "\u001b[0;32m/Users/Ben/anaconda/anaconda/lib/python2.7/site-packages/sklearn/neighbors/graph.pyc\u001b[0m in \u001b[0;36mkneighbors_graph\u001b[0;34m(X, n_neighbors, mode, metric, p, metric_params, include_self)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m     \u001b[0mquery\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_query_include_self\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minclude_self\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 115\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkneighbors_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_neighbors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_neighbors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    116\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/Ben/anaconda/anaconda/lib/python2.7/site-packages/sklearn/neighbors/base.pyc\u001b[0m in \u001b[0;36mkneighbors_graph\u001b[0;34m(self, X, n_neighbors, mode)\u001b[0m\n\u001b[1;32m    466\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'connectivity'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    467\u001b[0m             \u001b[0mA_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mones\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_samples1\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mn_neighbors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 468\u001b[0;31m             \u001b[0mA_ind\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkneighbors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_neighbors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_distance\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    469\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    470\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'distance'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/Ben/anaconda/anaconda/lib/python2.7/site-packages/sklearn/neighbors/base.pyc\u001b[0m in \u001b[0;36mkneighbors\u001b[0;34m(self, X, n_neighbors, return_distance)\u001b[0m\n\u001b[1;32m    337\u001b[0m             raise ValueError(\n\u001b[1;32m    338\u001b[0m                 \u001b[0;34m\"Expected n_neighbors <= %d. Got %d\"\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 339\u001b[0;31m                 \u001b[0;34m(\u001b[0m\u001b[0mtrain_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_neighbors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    340\u001b[0m             )\n\u001b[1;32m    341\u001b[0m         \u001b[0mn_samples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Expected n_neighbors <= 1. Got 31"
     ]
    }
   ],
   "source": [
    "for name, X in old_or_new_test.items():\n",
    "    knn_graph = kneighbors_graph(X, 30, include_self=False)\n",
    "\n",
    "    plt.scatter(X[:, 0], X[:, 1], c=model.labels_,\n",
    "                cmap=plt.cm.spectral)\n",
    "    plt.title(name,\n",
    "              fontdict=dict(verticalalignment='top'))\n",
    "    plt.axis('equal')\n",
    "    plt.axis('off')\n",
    "\n",
    "    plt.subplots_adjust(bottom=0, top=.89, wspace=0,\n",
    "                        left=0, right=1)\n",
    "    plt.suptitle('n_cluster=%i, connectivity=%r' %\n",
    "                 (n_clusters, connectivity is not None), size=17)\n",
    "\n",
    "\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#4. K-means clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KMeans(copy_x=True, init='k-means++', max_iter=100, n_clusters=9, n_init=10,\n",
       "    n_jobs=1, precompute_distances='auto', random_state=None, tol=0.0001,\n",
       "    verbose=0)"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "model = KMeans(n_clusters=9, init='k-means++', max_iter=100, n_init=10)\n",
    "model.fit(vecs_bible)  #the matrix can also come from tf-idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 555,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: pylab import has clobbered these variables: ['indices']\n",
      "`%matplotlib` prevents importing * from pylab and numpy\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: And Isaac called Jacob and blessed him and charged him and said to him Thou shalt not take a wife of the daughters of Canaan                                                                    Arise go",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-555-ad1d0c777752>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mkm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mKMeans\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_clusters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'k-means++'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_iter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_init\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0mkm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenesis_df\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[0;31m#km.fit(vecs_bible)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0minertia_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minertia_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/Ben/anaconda/anaconda/lib/python2.7/site-packages/sklearn/cluster/k_means_.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    783\u001b[0m         \"\"\"\n\u001b[1;32m    784\u001b[0m         \u001b[0mrandom_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_random_state\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 785\u001b[0;31m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_fit_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    786\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    787\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcluster_centers_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabels_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minertia_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_iter_\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/Ben/anaconda/anaconda/lib/python2.7/site-packages/sklearn/cluster/k_means_.pyc\u001b[0m in \u001b[0;36m_check_fit_data\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    753\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_check_fit_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    754\u001b[0m         \u001b[0;34m\"\"\"Verify that the number of samples given is larger than k\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 755\u001b[0;31m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'csr'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat64\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    756\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_clusters\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    757\u001b[0m             raise ValueError(\"n_samples=%d should be >= n_clusters=%d\" % (\n",
      "\u001b[0;32m/Users/Ben/anaconda/anaconda/lib/python2.7/site-packages/sklearn/utils/validation.pyc\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features)\u001b[0m\n\u001b[1;32m    342\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    343\u001b[0m                 \u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 344\u001b[0;31m         \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    345\u001b[0m         \u001b[0;31m# make sure we actually converted to numeric:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    346\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdtype_numeric\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"O\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: could not convert string to float: And Isaac called Jacob and blessed him and charged him and said to him Thou shalt not take a wife of the daughters of Canaan                                                                    Arise go"
     ]
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "import seaborn\n",
    "% pylab inline\n",
    "inertia_list = []\n",
    "\n",
    "for k in range(1,30):\n",
    "    km = KMeans(n_clusters=k, init = 'k-means++', max_iter = 100, n_init = 1)\n",
    "    km.fit(genesis_df)\n",
    "    #km.fit(vecs_bible)\n",
    "    inertia_list.append(km.inertia_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1625be490>]"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYoAAAECCAYAAADgnZClAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n4tX/B2J/SQO+8tfOAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2ef424f50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot(range(1,30), inertia_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Ben/anaconda/anaconda/lib/python2.7/site-packages/sklearn/cluster/k_means_.py:862: RuntimeWarning: Got data type int64, converted to float to avoid overflows\n",
      "  X = self._check_test_data(X)\n"
     ]
    }
   ],
   "source": [
    "kc_predict = model.predict(vecs_bible)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 2, 0, 0, 0, 2, 0, 0,\n",
       "       0, 0, 0, 0, 8, 0, 2, 0, 0, 7, 2, 0, 0, 0, 2, 2, 2, 2, 0, 0, 0, 0, 2,\n",
       "       7, 2, 8, 2, 0, 0, 2, 2, 7, 0, 2, 0, 0, 3, 2, 2, 0, 0, 2, 1, 2, 1, 1,\n",
       "       1, 2, 1, 2, 1, 2, 1, 1, 2, 2, 8, 2, 2, 2, 2, 2, 0, 1, 0, 2, 2, 2, 2,\n",
       "       2, 2, 0, 2, 2, 1], dtype=int32)"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kc_predict[2:100]  #first 20 docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Ben/anaconda/anaconda/lib/python2.7/site-packages/sklearn/cluster/k_means_.py:836: RuntimeWarning: Got data type int64, converted to float to avoid overflows\n",
      "  X = self._check_test_data(X)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([  2.59837443,   2.53925145,   2.25917279,   2.63333849,\n",
       "        36.95943723,   2.17993225,  70.01428426,   3.64544025,   2.62698645])"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "distances = model.transform(vecs_bible)\n",
    "distances[0] #will tell you, by cluster, how close a given doc is"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top terms per cluster:\n",
      "Cluster 0:  god  lord  hath  man  us  o  israel  people  jesus  also\n",
      "Cluster 1:  lord  hath  saith  o  people  israel  house  moses  day  man\n",
      "Cluster 2:  man  came  also  come  men  people  went  shalt  let  hath\n",
      "Cluster 3:  children  son  israel  lord  land  came  moses  house  man  men\n",
      "Cluster 4:  sons  brethren  twelve  twentieth  weretwelve  hisbrethren  hissons  thefifth  thirteenth  one\n",
      "Cluster 5:  king  israel  came  son  lord  house  judah  saying  david  people\n",
      "Cluster 6:  son  wasthe  theson  sonof  juda  whichwas  ofjoseph  levi  joseph  began\n",
      "Cluster 7:  lord  god  saith  israel  hath  house  saying  thus  land  people\n",
      "Cluster 8:  one  every  another  offering  man  two  lord  day  even  come\n"
     ]
    }
   ],
   "source": [
    "#sorting in descending order ie: -1\n",
    "#giving top ten words ie: :10\n",
    "print(\"Top terms per cluster:\")\n",
    "order_centroids = model.cluster_centers_.argsort()[:, ::-1]\n",
    "terms = vectorizer.get_feature_names()\n",
    "for i in range(9):\n",
    "    print \"Cluster %d:\" % i,\n",
    "    for ind in order_centroids[i, :10]:\n",
    "        print ' %s' % terms[ind],\n",
    "    print"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#preprocessing\n",
    "document = [word for sublist in document for word in sublist]\n",
    "                document = ' '.join(document)\n",
    "                word_list = document.split()\n",
    "                document = ' '.join([word for word in word_list if word not in stopwords])\n",
    "                #                 document_revised = []\n",
    "                #                 for i in document:\n",
    "                #                     words = i.split()\n",
    "                #                     for word in words:\n",
    "                #                         if word not in stopwords:\n",
    "                #                             document_revised.append(word)\n",
    "                document = [re.sub(r'\\W+', '', word) for word in document]\n",
    "                document = [word for word in document if word.isalpha()]\n",
    "                document = [word.lower() for word in document]\n",
    "                texts.append(document)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "document = [['blurpity blurp, blurp blurp blurp, 0.'], ['how do you do?'], \n",
    "            ['May I take the hat, Sir. May I take your hat, Sir!?']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "blurpity blurp, blurp blurp blurp, 0. do? May I take hat, Sir. May I take hat, Sir!?\n"
     ]
    }
   ],
   "source": [
    "document = [word for sublist in document for word in sublist]\n",
    "document = ' '.join(document)\n",
    "word_list = document.split()\n",
    "document = ' '.join([word for word in word_list if word not in stopwords])\n",
    "\n",
    "# sentence = 'word1 word2 word3 word1 word2 word4'\n",
    "# >>> remove_list = ['word1', 'word2']\n",
    "# >>> word_list = sentence.split()\n",
    "# >>> ' '.join([i for i in word_list if i not in remove_list])\n",
    "# 'word3 word4'\n",
    "\n",
    "# if word in stopwords, remove word from \n",
    "# document = [word for word in document.split() if word not in stopwords]\n",
    "print document\n",
    "\n",
    "#document = [sublist.split() for sublist in document]\n",
    "#document = [word for word in sublist if word not in stopwords for sublist in document]\n",
    "#document = [word for sublist in document for word in sublist]\n",
    "\n",
    "# document_revised = []\n",
    "# for i in document:\n",
    "#     for word in i.split():\n",
    "#         if word not in stopwords:\n",
    "#             document_revised.append(word)\n",
    "# print document_revised\n",
    "# document_revised = [re.sub(r'\\W+', '', word) for word in document_revised]\n",
    "# document_revised = [word for word in document_revised if word.isalpha()]\n",
    "# document_revised = [word.lower() for word in document_revised]\n",
    "# print document_revised"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 447,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "blurpity blurp, blurp blurp blurp, 0. how do you do? may i take your hat, sir. may i take your hat, sir!? \n",
      "['blurpity blurp, blurp blurp blurp, 0.', 'how do you do?', 'may i take your hat, sir. may i take your hat, sir!?']\n"
     ]
    }
   ],
   "source": [
    "single_string = ''\n",
    "for words in document:\n",
    "    single_string += words + ' '\n",
    "print single_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 438,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['blurpity', 'blurp,', 'blurp', 'blurp', 'blurp,', '0.']\n",
      "['how', 'do', 'you', 'do?']\n",
      "['may', 'i', 'take', 'your', 'hat,', 'sir.', 'may', 'i', 'take', 'your', 'hat,', 'sir!?']\n"
     ]
    }
   ],
   "source": [
    "for i in document:\n",
    "    print i.split()\n",
    "    #for word in i:\n",
    "    #    print word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#document = [word.lower() for word in document]\n",
    "# remove stopwords and non-letters\n",
    "#document = [re.sub(r'\\W+', '', word) for word in document\n",
    "#            if word.isalpha() and word not in stopwords]\n",
    "corpus_by_sentence.append(document)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "###Possible Params:\n",
    "# filename\n",
    "# format='gutenberg' --> controls start and end strs\n",
    "# stemming='lancaster', 'porter', etc.\n",
    "# min_freq=None, 2, etc.\n",
    "# max_freq=None, 100, 1000, etc.\n",
    "#lower=True  --> lowercase or not /alternately, capitalized=\n",
    "\n",
    "\n",
    "bible = open('bible.txt')\n",
    "\n",
    "startline = 100\n",
    "endline = 1000000\n",
    "verse = []\n",
    "#user can specify stemming or not; if stemming, can say 'porter' or 'lancaster'\n",
    "#unstemmed_verses = []\n",
    "#stemmed_verses = []\n",
    "#user can specify min_freq=None, or a number\n",
    "min_freq = 2\n",
    "#could do same for max_freq, and keep most popular words in a different place\n",
    "stopwords = set(nltk.corpus.stopwords.words('english'))\n",
    "#specify capitalized or not\n",
    "capitalized = []\n",
    "\n",
    "for i, line in enumerate(bible):\n",
    "    if start in line:\n",
    "        startline = i\n",
    "    if end in line:\n",
    "        endline = i\n",
    "    if i > startline and i < endline:\n",
    "        if line.strip():   # returns false if blank line\n",
    "                           # this constitutes the BEGINNING OF A DOCUMENT.\n",
    "            verse.append(line)\n",
    "\n",
    "        \n",
    "        else:  # end of verse\n",
    "               # this constitutes the END OF A DOCUMENT.\n",
    "            if len(verse) > 0 and isinstance(verse[0], str):\n",
    "                # render lowercase and tokenize\n",
    "                #verse = [line.lower() for line in verse]\n",
    "                verse = [line.split() for line in verse]  \n",
    "                # remove stopwords and non-letters\n",
    "                new_verse = []\n",
    "                for line in verse:\n",
    "                    for word in line:\n",
    "                        word = re.sub(r'\\W+', '', word)  \n",
    "                        if word.isalpha() and word not in stopwords:\n",
    "                            new_verse.append(word)\n",
    "                \n",
    "                #stem down, if wanted\n",
    "                #stemmer = nltk.stem.porter.PorterStemmer()\n",
    "                #stemmer = nltk.stem.lancaster.LancasterStemmer()\n",
    "                #stemmed_verse = [stemmer.stem(word) for word in new_verse]\n",
    "                \n",
    "                capitalized.append(new_verse)\n",
    "                #unstemmed_verses.append(new_verse)\n",
    "                #stemmed_verses.append(stemmed_verse)\n",
    "                ###eventually, for mongo: bible.save(verse)\n",
    "                verse = []\n",
    "\n",
    "#Future optimization: stemming (this works, just dont want to do until further modularized)\n",
    "# # remove words that appear less than a minimum frequency, if wanted\n",
    "# frequency = defaultdict(int)\n",
    "# for document in verses:\n",
    "#     for token in document:\n",
    "#         frequency[token] += 1\n",
    "# verses = [[token for token in document if frequency[token] >= min_freq] \n",
    "#            for document in verses]\n",
    "        \n",
    "bible.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#str.isalpha()\n",
    "#re.sub(r'\\W+', '', word)   \n",
    "#THIS PART WAS SPECIFIC TO THE BIBLE    \n",
    "#if re.match(r'\\b\\d{1,3}[:]\\d{1,2}\\b', line):   # new verse\n",
    "#    verse = [line]\n",
    "#else:\n",
    "#   verse.append(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['old', 'testament', 'king', 'james', 'version', 'bible'],\n",
       " ['old', 'testa', 'king', 'jam', u'vert', 'bibl'])"
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#our corpuses:\n",
    "corp = unstemmed_verses\n",
    "stemmed_corp = stemmed_verses\n",
    "unstemmed_verses[0], stemmed_verses[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The', 'Old', 'Testament', 'King', 'James', 'Version', 'Bible']"
      ]
     },
     "execution_count": 338,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "capitalized[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('bible_corpus_stemmed.pkl', 'w') as picklefile:\n",
    "    pickle.dump(stemmed_verses, picklefile)\n",
    "with open('bible_corpus_unstemmed.pkl', 'w') as picklefile:\n",
    "    pickle.dump(unstemmed_verses, picklefile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#2. preliminary exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###2a. part of speech tagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from nltk.tag import pos_tag  #takes about 5 mins\n",
    "#pos_tag_words = [pos_tag(doc) for doc in tqdm(corp)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "LookupError",
     "evalue": "\n**********************************************************************\n  Resource u'taggers/averaged_perceptron_tagger/averaged_perceptro\n  n_tagger.pickle' not found.  Please use the NLTK Downloader to\n  obtain the resource:  >>> nltk.download()\n  Searched in:\n    - '/Users/Ben/nltk_data'\n    - '/usr/share/nltk_data'\n    - '/usr/local/share/nltk_data'\n    - '/usr/lib/nltk_data'\n    - '/usr/local/lib/nltk_data'\n**********************************************************************",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mLookupError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-351-9e8e14220156>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mw\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'hello'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mpos_tag\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/Users/Ben/anaconda/anaconda/lib/python2.7/site-packages/nltk/tag/__init__.pyc\u001b[0m in \u001b[0;36mpos_tag\u001b[0;34m(tokens, tagset)\u001b[0m\n\u001b[1;32m    108\u001b[0m     \u001b[0;34m:\u001b[0m\u001b[0mrtype\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m     \"\"\"\n\u001b[0;32m--> 110\u001b[0;31m     \u001b[0mtagger\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPerceptronTagger\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    111\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0m_pos_tag\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokens\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtagset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtagger\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/Ben/anaconda/anaconda/lib/python2.7/site-packages/nltk/tag/perceptron.pyc\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, load)\u001b[0m\n\u001b[1;32m    139\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mload\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 141\u001b[0;31m             \u001b[0mAP_MODEL_LOC\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'taggers/averaged_perceptron_tagger/'\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mPICKLE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    142\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mAP_MODEL_LOC\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/Ben/anaconda/anaconda/lib/python2.7/site-packages/nltk/data.pyc\u001b[0m in \u001b[0;36mfind\u001b[0;34m(resource_name, paths)\u001b[0m\n\u001b[1;32m    634\u001b[0m     \u001b[0msep\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'*'\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m70\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    635\u001b[0m     \u001b[0mresource_not_found\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'\\n%s\\n%s\\n%s'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0msep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 636\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mLookupError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresource_not_found\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    637\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    638\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mLookupError\u001b[0m: \n**********************************************************************\n  Resource u'taggers/averaged_perceptron_tagger/averaged_perceptro\n  n_tagger.pickle' not found.  Please use the NLTK Downloader to\n  obtain the resource:  >>> nltk.download()\n  Searched in:\n    - '/Users/Ben/nltk_data'\n    - '/usr/share/nltk_data'\n    - '/usr/local/share/nltk_data'\n    - '/usr/lib/nltk_data'\n    - '/usr/local/lib/nltk_data'\n**********************************************************************"
     ]
    }
   ],
   "source": [
    "w = 'hello'\n",
    "pos_tag(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'capitalized' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-348-0127c5ef0af2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpos_tag_incl_capitals\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mpos_tag\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mdoc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcapitalized\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'capitalized' is not defined"
     ]
    }
   ],
   "source": [
    "pos_tag_incl_capitals = [pos_tag(doc) for doc in tqdm(capitalized)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('The', 'DT'),\n",
       " ('Old', 'NNP'),\n",
       " ('Testament', 'NNP'),\n",
       " ('King', 'NNP'),\n",
       " ('James', 'NNP'),\n",
       " ('Version', 'NNP'),\n",
       " ('Bible', 'NNP')]"
      ]
     },
     "execution_count": 343,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos_tag_incl_capitals[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import pickle\n",
    "# with open('bible_words_by_part_of_speech.pkl', 'w') as picklefile:\n",
    "#     pickle.dump(pos_tag_words, picklefile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('bible_words_by_part_of_speech.pkl', 'w') as picklefile:\n",
    "    pickle.dump(pos_tag_incl_capitals, picklefile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_pos_popularity(corp):\n",
    "    pos_popularity = defaultdict(int)\n",
    "    for doc in corp:\n",
    "        for word, pos in doc:\n",
    "            pos_popularity[pos] += 1\n",
    "    return pos_popularity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#pos_popularity = get_pos_popularity(pos_tag_words)\n",
    "#bad b/c doesn't include proper nouns!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pos_popularity_with_capitals = get_pos_popularity(pos_tag_incl_capitals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(<type 'int'>, {'PRP$': 752, 'VBG': 7344, 'VBD': 29964, 'VBN': 12029, 'VBP': 15202, 'WDT': 227, 'JJ': 18432, 'WP': 519, 'VBZ': 2231, 'DT': 5519, 'RP': 284, 'NN': 129122, 'TO': 164, 'PRP': 13525, 'RB': 16367, 'NNS': 36531, 'NNP': 56326, 'VB': 13814, 'WRB': 646, 'CC': 14547, 'PDT': 8, 'RBS': 1, 'RBR': 112, 'CD': 4983, 'EX': 204, 'IN': 21777, 'WP$': 279, 'MD': 11220, 'NNPS': 454, 'JJS': 622, 'JJR': 641, 'UH': 12})"
      ]
     },
     "execution_count": 341,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos_popularity_with_capitals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      ":0: FutureWarning: IPython widgets are experimental and may change in the future.\n"
     ]
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "#I JUST WANT TO MAKE A FUCKING SIMPLE BAR CHART AND IT'S FUCKING ANNOYINGLY HARD TO DO SO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# sns.countplot(y=\"party\", hue=\"party\", data=reps_df)\n",
    "# sns.plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pos_dict = {\n",
    "'CC': 'coordinating conjunction---etc',\n",
    "'CD': 'cardinal number---1, third',\n",
    "'DT': 'determiner (article)---the, a, an',\n",
    "'EX': 'existential there---there is',\n",
    "'FW': 'foreign word---d’hoevre',\n",
    "'IN': 'preposition/subordinating conjunction---in, of, like',\n",
    "'JJ': 'adjective---big',\n",
    "'JJR': 'adjective, comparative---bigger',\n",
    "'JJS': 'adjective, superlative---biggest',\n",
    "'LS': 'list marker---1)',\n",
    "'MD': 'modal (subjunctive)---could, will',\n",
    "'NN': 'noun, singular or mass---door',\n",
    "'NNS': 'noun plural---doors',\n",
    "'NNP': 'proper noun, singular---John',\n",
    "'NNPS': 'proper noun, plural---Vikings',\n",
    "'PDT': 'predeterminer---both the boys',\n",
    "'POS': 'possessive ending---friend‘s',\n",
    "'PRP': 'personal pronoun---I, he, it',\n",
    "'PRP$': 'possessive pronoun---my, his',\n",
    "'RB': 'adverb---however, usually, naturally, here, good',\n",
    "'RBR': 'adverb, comparative---better',\n",
    "'RBS': 'adverb, superlative---best',\n",
    "'RP': 'particle---give up',\n",
    "'TO': 'to---to go, to him',\n",
    "'UH': 'interjection---uhhuhhuhh',\n",
    "'VB': 'verb, base form---take',\n",
    "'VBD': 'verb, past tense---took',\n",
    "'VBG': 'verb, gerund/present participle---taking',\n",
    "'VBN': 'verb, past participle---taken',\n",
    "'VBP': 'verb, sing. present, non-3d---take',\n",
    "'VBZ': 'verb, 3rd person sing. present---takes',\n",
    "'WDT': 'wh-determiner---which',\n",
    "'WP': 'wh-pronoun---who, what',\n",
    "'WP$': 'possessive wh-pronoun---whose',\n",
    "'WRB': 'wh-abverb---where, when'\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###2b. sentiment analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# everything together as one string\n",
    "flattened_corp = ''.join(str(corp).translate(None,\"[]'\").split(','))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sentiment(polarity=0.12117085186315783, subjectivity=0.520236563826305)"
      ]
     },
     "execution_count": 259,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TextBlob(flattened_corp).sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 429,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                             "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                             "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "2"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                             "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "3"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                             "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "4"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                             "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "5"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                             "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "6"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                             "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "overall_sentiment = {}\n",
    "for i, b in enumerate(bibles_data):\n",
    "    print i\n",
    "    for name, corp in tqdm(b.items()):\n",
    "        flattened = ' '.join(corp)\n",
    "        overall_sentiment[name] = TextBlob(flattened).sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 431,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New International Version\n",
      "Sentiment(polarity=0.05308589129172552, subjectivity=0.26887834650072606)\n",
      "\n",
      "\n",
      "Hebrew Names Version\n",
      "Sentiment(polarity=0.1120478882007661, subjectivity=0.507007798795785)\n",
      "\n",
      "\n",
      "Good News Translation\n",
      "Sentiment(polarity=0.07527512356919792, subjectivity=0.4450116209132388)\n",
      "\n",
      "\n",
      "GOD'S WORD Translation\n",
      "Sentiment(polarity=0.0671739959380672, subjectivity=0.48785011113700266)\n",
      "\n",
      "\n",
      "King James Version\n",
      "Sentiment(polarity=0.11447387185513332, subjectivity=0.5139551135032695)\n",
      "\n",
      "\n",
      "The Darby Translation\n",
      "Sentiment(polarity=0.1074006628663569, subjectivity=0.5030664198887135)\n",
      "\n",
      "\n",
      "The Webster Bible\n",
      "Sentiment(polarity=0.12066581270199164, subjectivity=0.5183539437574518)\n",
      "\n",
      "\n",
      "Wycliffe\n",
      "Sentiment(polarity=0.12039701686302584, subjectivity=0.4963956405280762)\n",
      "\n",
      "\n",
      "The Bible in Basic English\n",
      "Sentiment(polarity=0.05689191480548633, subjectivity=0.4983546374868515)\n",
      "\n",
      "\n",
      "World English Bible\n",
      "Sentiment(polarity=0.11072252151980345, subjectivity=0.506188593731399)\n",
      "\n",
      "\n",
      "Douay-Rhiems Catholic Bible\n",
      "Sentiment(polarity=0.11637821453086036, subjectivity=0.5080830611304791)\n",
      "\n",
      "\n",
      "Lexham English Bible\n",
      "Sentiment(polarity=0.08722574533446657, subjectivity=0.4582605253330418)\n",
      "\n",
      "\n",
      "New American Standard Bible\n",
      "Sentiment(polarity=0.05662609809703124, subjectivity=0.27220895875287876)\n",
      "\n",
      "\n",
      "Revised Standard Version\n",
      "Sentiment(polarity=0.10403227744381119, subjectivity=0.5018201836443783)\n",
      "\n",
      "\n",
      "New Century Version\n",
      "Sentiment(polarity=0.08155943688577301, subjectivity=0.5048091741875151)\n",
      "\n",
      "\n",
      "New International Reader's Version\n",
      "Sentiment(polarity=0.08772479344582323, subjectivity=0.5036418422807474)\n",
      "\n",
      "\n",
      "Jubilee Bible 2000\n",
      "Sentiment(polarity=0.11029657409269655, subjectivity=0.5089922105323487)\n",
      "\n",
      "\n",
      "English Standard Version\n",
      "Sentiment(polarity=0.05770092624196293, subjectivity=0.2635695698074727)\n",
      "\n",
      "\n",
      "New Living Translation\n",
      "Sentiment(polarity=0.09032622696810359, subjectivity=0.47424381358604634)\n",
      "\n",
      "\n",
      "American Standard Version\n",
      "Sentiment(polarity=0.11375655826015464, subjectivity=0.5120250685225184)\n",
      "\n",
      "\n",
      "Holman Christian Standard Bible\n",
      "Sentiment(polarity=0.08579039401405827, subjectivity=0.4770370075655903)\n",
      "\n",
      "\n",
      "New Revised Standard\n",
      "Sentiment(polarity=0.10026968694868321, subjectivity=0.4859899146766633)\n",
      "\n",
      "\n",
      "Young's Literal Translation\n",
      "Sentiment(polarity=0.10414343192818071, subjectivity=0.49767754695153454)\n",
      "\n",
      "\n",
      "The Complete Jewish Bible\n",
      "Sentiment(polarity=0.08622119745528813, subjectivity=0.4809727976328396)\n",
      "\n",
      "\n",
      "The Message Bible\n",
      "Sentiment(polarity=0.06791908600530851, subjectivity=0.4980391476713789)\n",
      "\n",
      "\n",
      "New King James Version\n",
      "Sentiment(polarity=0.11202485258793632, subjectivity=0.49451764575052015)\n",
      "\n",
      "\n",
      "Third Millennium Bible\n",
      "Sentiment(polarity=0.1156268503636869, subjectivity=0.5111361766140236)\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for name, sentiment in overall_sentiment.items():\n",
    "    print name\n",
    "    print sentiment\n",
    "    print '\\n'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 423,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#bibles_data[0]['American Standard Version']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###2c. word counts\n",
    "idk where the fuck these come frome so ima do it up in gensim..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#3. stick it into gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 398,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'words'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-398-b560e937b8b6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDoc2Vec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcorp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwindow\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmin_count\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/Users/Ben/anaconda/anaconda/lib/python2.7/site-packages/gensim/models/doc2vec.pyc\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, documents, size, alpha, window, min_count, max_vocab_size, sample, seed, workers, min_alpha, dm, hs, negative, dbow_words, dm_mean, dm_concat, dm_tag_count, docvecs, docvecs_mapfile, comment, trim_rule, **kwargs)\u001b[0m\n\u001b[1;32m    594\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcomment\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcomment\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    595\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdocuments\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 596\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild_vocab\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdocuments\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrim_rule\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrim_rule\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    597\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdocuments\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    598\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/Ben/anaconda/anaconda/lib/python2.7/site-packages/gensim/models/word2vec.pyc\u001b[0m in \u001b[0;36mbuild_vocab\u001b[0;34m(self, sentences, keep_raw_vocab, trim_rule)\u001b[0m\n\u001b[1;32m    506\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    507\u001b[0m         \"\"\"\n\u001b[0;32m--> 508\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscan_vocab\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentences\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrim_rule\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrim_rule\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# initial survey\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    509\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscale_vocab\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeep_raw_vocab\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkeep_raw_vocab\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrim_rule\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrim_rule\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# trim by min_count & precalculate downsampling\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    510\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfinalize_vocab\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# build tables & arrays\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/Ben/anaconda/anaconda/lib/python2.7/site-packages/gensim/models/doc2vec.pyc\u001b[0m in \u001b[0;36mscan_vocab\u001b[0;34m(self, documents, progress_per, trim_rule)\u001b[0m\n\u001b[1;32m    637\u001b[0m                 \u001b[0minterval_start\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdefault_timer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    638\u001b[0m                 \u001b[0minterval_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtotal_words\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 639\u001b[0;31m             \u001b[0mdocument_length\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdocument\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    640\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    641\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mtag\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdocument\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtags\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'words'"
     ]
    }
   ],
   "source": [
    "model = models.Doc2Vec(corp, size=100, window=8, min_count=5, workers=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###3a. token dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# corpora = corp, stemmed_corp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#corp[10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import logging\n",
    "from gensim import corpora, models, similarities\n",
    "#setting basic config\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#i would like to remove all proper nouns from the corpus...clearly not working...why?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "corp_sans_proper_nouns = capitalized\n",
    "for i, doc in enumerate(corp_sans_proper_nouns):\n",
    "    for j, word in enumerate(doc):\n",
    "        if pos_tag_incl_capitals[i][j][1] == 'NNP':\n",
    "            corp_sans_proper_nouns[i].remove(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#pos_tag_incl_capitals[222]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-362-9b866a83a06a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mword_pos\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mword_pos\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'NNP'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m             \u001b[0mcorp_sans_proper_nouns\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mremove\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcorp_sans_proper_nouns\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "corp_sans_proper_nouns = capitalized\n",
    "for i, doc in enumerate(pos_tag_incl_capitals):\n",
    "    for j, word_pos in enumerate(doc):\n",
    "        if word_pos[1] == 'NNP':\n",
    "            corp_sans_proper_nouns[i].remove(corp_sans_proper_nouns[i][j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#1. collect statistics about all tokens\n",
    "dictionary = corpora.Dictionary(doc for doc in corp)\n",
    "\n",
    "#2a. remove stop words and words that appear only once\n",
    "# stop_ids = [dictionary.token2id[stopword] for stopword in stoplist\n",
    "#             if stopword in dictionary.token2id]\n",
    "once_ids = [tokenid for tokenid, docfreq in dictionary.dfs.iteritems() if docfreq == 1]\n",
    "\n",
    "#2b. remove stop words and words that appear only once\n",
    "dictionary.filter_tokens(once_ids)  # + stop_ids\n",
    "\n",
    "#3. remove gaps in id sequence after words that were removed\n",
    "dictionary.compactify() \n",
    "\n",
    "\n",
    "# #The shorter way\n",
    "# dictionary = corpora.Dictionary(texts)\n",
    "# dictionary.save('deerwester.dict') # store the dictionary, for future reference\n",
    "# print(dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dictionary(8448 unique tokens: [u'giddel', u'yellow', u'four', u'aijalon', u'spiders']...)\n"
     ]
    }
   ],
   "source": [
    "print dictionary\n",
    "#mapping between words : IDs\n",
    "#print(dictionary.token2id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###3b. vectorized corpus\n",
    "The function `doc2bow()` simply counts the number of occurences of each distinct word, converts the word to its integer word id and returns the result as a sparse vector.\n",
    "The sparse vector therefore reads: in the document “Human computer interaction”, the words computer (id 1) and human (id 2) appear once; the other ten dictionary words appear (implicitly) zero times."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Memory-Friendly Streaming\n",
    "# class MyCorpus(object):\n",
    "#     def __iter__(self):\n",
    "#         for line in open('mycorpus.txt'):\n",
    "#             # assume there's one document per line, tokens separated by whitespace\n",
    "#             yield dictionary.doc2bow(line.lower().split())\n",
    "\n",
    "# corpus_memory_friendly = MyCorpus() # doesn't load the corpus into memory!\n",
    "# print(corpus_memory_friendly)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vec_corp = [dictionary.doc2bow(doc) for doc in corp]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(653, 2),\n",
       " (2717, 2),\n",
       " (3331, 1),\n",
       " (3459, 2),\n",
       " (3976, 3),\n",
       " (5199, 1),\n",
       " (5279, 1),\n",
       " (6709, 2),\n",
       " (7392, 1),\n",
       " (7734, 1)]"
      ]
     },
     "execution_count": 311,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vec_corp[222]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "u'begat'"
      ]
     },
     "execution_count": 312,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dictionary[3976]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###3c. modeled transformations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####Term Frequency / Inverse Document Frequency (tf-idf)\n",
    "I think would do better w/o proper nouns. (De)capitalization probs doesn't matter either, so can use the `capitalized` corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tfidf = models.TfidfModel(vec_corp) # -- initialize (train) a model\n",
    "corpus_tfidf = tfidf[vec_corp]\n",
    "# for doc in corpus_tfidf:  #streamed on-the-fly\n",
    "#     print doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#corpus_tfidf[222]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "max_tfidf = [(0, 0)]\n",
    "for doc in corpus_tfidf:\n",
    "    for term in doc:\n",
    "        current_max = max_tfidf[0][1]\n",
    "        if term[1] > current_max:\n",
    "            max_tfidf[0] = term\n",
    "        if term[1] == 1.0 and term not in max_tfidf:\n",
    "            max_tfidf.append(term)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 334,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(max_tfidf) #all these got 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "son\n",
      "ezra\n",
      "selah\n",
      "proverbs\n",
      "preacher\n",
      "hosea\n",
      "joel\n",
      "amos\n",
      "obadiah\n",
      "jonah\n",
      "micah\n",
      "nahum\n",
      "habakkuk\n",
      "zephaniah\n",
      "haggai\n",
      "zechariah\n",
      "malachi\n",
      "lord\n",
      "amen\n",
      "despise\n"
     ]
    }
   ],
   "source": [
    "for term_id, _ in max_tfidf:\n",
    "    print dictionary[term_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# may want to remove all NNP, all proper nouns..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####Latent Semantic Indexing (LSI)\n",
    "So,\n",
    "- remove proper nouns.\n",
    "\n",
    "also,\n",
    "- get rid of the 'formal' stopwords like shall, thy, thou, thee, ye, thine, said, hast, unto, upon... these are really clogging things up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# initialize an LSI transformation\n",
    "lsi = models.LsiModel(corpus_tfidf, id2word=dictionary, num_topics=6) \n",
    "\n",
    "# create a double wrapper over the original corpus: \n",
    "# bow --> tfidf --> fold-in-lsi\n",
    "corpus_lsi = lsi[corpus_tfidf] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  u'0.284*\"shall\" + 0.243*\"thou\" + 0.243*\"unto\" + 0.243*\"thy\" + 0.242*\"lord\" + 0.222*\"thee\" + 0.182*\"god\" + 0.180*\"said\" + 0.178*\"ye\" + 0.129*\"israel\"'),\n",
       " (1,\n",
       "  u'-0.488*\"thy\" + -0.458*\"thou\" + -0.294*\"thee\" + 0.289*\"ye\" + -0.278*\"shalt\" + 0.261*\"shall\" + -0.179*\"hast\" + 0.126*\"israel\" + -0.116*\"thine\" + 0.105*\"children\"'),\n",
       " (2,\n",
       "  u'-0.619*\"shall\" + 0.261*\"king\" + -0.260*\"ye\" + 0.207*\"israel\" + 0.187*\"son\" + 0.178*\"came\" + 0.170*\"said\" + 0.151*\"david\" + 0.140*\"went\" + 0.133*\"children\"'),\n",
       " (3,\n",
       "  u'-0.311*\"ye\" + 0.301*\"shall\" + 0.229*\"shalt\" + -0.197*\"god\" + -0.190*\"said\" + 0.175*\"hundred\" + 0.170*\"children\" + 0.159*\"offering\" + 0.155*\"thousand\" + -0.146*\"us\"'),\n",
       " (4,\n",
       "  u'0.589*\"thy\" + -0.435*\"thou\" + -0.390*\"shalt\" + -0.177*\"said\" + 0.160*\"o\" + -0.141*\"unto\" + -0.106*\"ye\" + -0.100*\"hast\" + -0.097*\"jesus\" + 0.091*\"lord\"'),\n",
       " (5,\n",
       "  u'0.380*\"children\" + -0.331*\"king\" + 0.297*\"israel\" + 0.284*\"moses\" + 0.231*\"lord\" + -0.216*\"shall\" + 0.191*\"ye\" + -0.155*\"son\" + -0.152*\"said\" + 0.120*\"aaron\"')]"
      ]
     },
     "execution_count": 391,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lsi.print_topics(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 396,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['old', 'version']"
      ]
     },
     "execution_count": 396,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corp[0]\n",
    "#well that's fucked. that's not supposed to happen. have to MODULARIZE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 394,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-394-2ed1600ef381>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# transform corpus to LSI space and index it\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msimilarities\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMatrixSimilarity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlsi\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcorp\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_features\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/Users/Ben/anaconda/anaconda/lib/python2.7/site-packages/gensim/models/lsimodel.pyc\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, bow, scaled, chunksize)\u001b[0m\n\u001b[1;32m    433\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    434\u001b[0m         \u001b[0;31m# convert input to scipy.sparse CSC, then do \"sparse * dense = dense\" multiplication\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 435\u001b[0;31m         \u001b[0mvec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmatutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcorpus2csc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbow\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_terms\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_terms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprojection\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mu\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    436\u001b[0m         \u001b[0mtopic_dist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mvec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprojection\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mu\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_topics\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m  \u001b[0;31m# (x^T * u).T = u^-1 * x\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    437\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/Ben/anaconda/anaconda/lib/python2.7/site-packages/gensim/matutils.pyc\u001b[0m in \u001b[0;36mcorpus2csc\u001b[0;34m(corpus, num_terms, dtype, num_docs, num_nnz, printprogress)\u001b[0m\n\u001b[1;32m    114\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mprintprogress\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mdocno\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mprintprogress\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m                 \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"PROGRESS: at document #%i\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdocno\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 116\u001b[0;31m             \u001b[0mindices\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfeature_id\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfeature_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdoc\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    117\u001b[0m             \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfeature_weight\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeature_weight\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdoc\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m             \u001b[0mnum_nnz\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: too many values to unpack"
     ]
    }
   ],
   "source": [
    "# transform corpus to LSI space and index it\n",
    "index = similarities.MatrixSimilarity(lsi[corp], num_features=3) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Next Steps: (for tomorrow [tues])\n",
    "\n",
    "1. remove proper nouns.\n",
    "\n",
    "2. get rid of the 'formal' stopwords like shall, thy, thou, thee, ye, thine, said, hast, unto, upon... these are really clogging things up\n",
    "\n",
    "3. ~modularize~\n",
    "\n",
    "4. try with stemmed corpus!\n",
    "\n",
    "still have to try\n",
    "\n",
    "5. lda (& pca?)\n",
    "6. hdp\n",
    "7. w2v\n",
    "\n",
    "and then\n",
    "\n",
    "8. PCA & KNN(++)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Preliminary Stopwords List:\n",
    "\n",
    "shall, thy, thou, thee, ye, thine, said, hast, unto, upon\n",
    "shant, "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 577,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       ..., \n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0]])"
      ]
     },
     "execution_count": 577,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics.pairwise import pairwise_distances\n",
    "\n",
    "text = [line for line in open('bible.txt').readlines()]\n",
    "vectorizer = CountVectorizer()\n",
    "X = vectorizer.fit_transform(text)\n",
    "\n",
    "X.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pairwise_distances(X, Y=None, metric='cosine')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pairwise_distances(X, Y=None, metric='euclidean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "X = X.toarray()\n",
    "np.corrcoef(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
